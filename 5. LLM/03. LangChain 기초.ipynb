{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8496dfb",
   "metadata": {},
   "source": [
    "# Langchainì´ë€?\n",
    "ë³´í†µ ì–¸ì–´ ëª¨ë¸ì´ í•´ê²°í•  ìˆ˜ ìˆëŠ” ê²ƒì€ ë‹¨ìˆœí•œ ì§€ì‹œë§Œìœ¼ë¡œëŠ” í•´ê²°í•  ìˆ˜ ì—†ëŠ” ë¬¸ì œë¥¼ í•´ê²°í•˜ê³¤ í•©ë‹ˆë‹¤. ë²ˆì—­, ìš”ì•½, ë§íˆ¬ ë³€ê²½, ì‘ë¬¸ ë“±ì´ ì—¬ê¸°ì— í•´ë‹¹í•©ë‹ˆë‹¤.\n",
    "\n",
    "í•˜ì§€ë§Œ ì–¸ì–´ ëª¨ë¸ì€ í˜„ì¬ ì•Œê³  ìˆëŠ” ì •ë³´ë¡œë§Œ ë‹µë³€ì„ í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— í•™ìŠµ ë‹¹ì‹œì˜ ì§€ì‹ì„ ë²—ì–´ë‚œ ì •ë³´ì— ëŒ€í•´ì„œëŠ” ë‹µë³€ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ëŠ” ë‹¨ì ì„ ì•ˆê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŸ¬í•œ ì–¸ì–´ ëª¨ë¸ì˜ í•œê²Œë¥¼ ë„˜ì–´ì„œê¸° ìœ„í•´ RAG(Retrieval Augmented Generation), ReACT(Reasoning and Acting) ë“±ì˜ ë°©ë²•ë¡ ë“¤ì´ ë“±ì¥í•˜ê²Œ ë˜ì—ˆìœ¼ë©°, ì´ëŸ¬í•œ ë°©ë²•ë¡ ë“¤ì„ ì ìš©í•˜ë©´ì„œ ì–¸ì–´ ëª¨ë¸ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí•˜ê¸° ìœ„í•´ ë“±ì¥í•œ ê²ƒì´ OpenAIì˜ Langchain ì…ë‹ˆë‹¤.\n",
    "\n",
    "* Model I/O: í”„ë¡¬í”„íŠ¸ ì¤€ë¹„, ì–¸ì–´ ëª¨ë¸ í˜¸ì¶œ, ê²°ê³¼ ìˆ˜ì‹ \n",
    "* Retrieval: ì™¸ë¶€ ì§€ì‹ì„ LLMì— ì£¼ì…. ChatPDF, CSV íŒŒì¼ ê¸°ë°˜ ë‹µë³€\n",
    "* Memory: ê³¼ê±°ì˜ ëŒ€í™”ë¥¼ ì¥/ë‹¨ê¸°ë¡œ ê¸°ì–µ. ì´ì „ ë¬¸ë§¥ì„ ê³ ë ¤í•œ ë‹µë³€.\n",
    "* Chains: ì—¬ëŸ¬ ëª¨ë“ˆì„ í†µí•©í•˜ëŠ” ê¸°ëŠ¥. ë‹¨ë… ì‚¬ìš© ìš©ë„ X\n",
    "* Agents: ReACTë‚˜ Function Calling ê¸°ë²•ì„ ì‚¬ìš©í•´ ì™¸ë¶€ì™€ ìƒí˜¸ ì‘ìš©.\n",
    "* Callbacks: ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ ë°œìƒì„ ì²˜ë¦¬ ê°€ëŠ¥. ë‹¨ë… ì‚¬ìš© ìš©ë„ X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100b958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\user\\anaconda3\\lib\\site-packages (1.75.0)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai) (4.11.0)\n",
      "Collecting langchain-core<1.0.0,>=0.3.51 (from langchain)\n",
      "  Downloading langchain_core-0.3.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.31-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (3.10.5)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.16-cp312-cp312-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.9.0-cp312-cp312-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 894.9/894.9 kB 10.0 MB/s eta 0:00:00\n",
      "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 2.4/2.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 11.2 MB/s eta 0:00:00\n",
      "Downloading langchain_openai-0.3.13-py3-none-any.whl (61 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain_core-0.3.52-py3-none-any.whl (433 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.31-py3-none-any.whl (358 kB)\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading orjson-3.10.16-cp312-cp312-win_amd64.whl (133 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Installing collected packages: typing-inspect, orjson, marshmallow, httpx-sse, tiktoken, dataclasses-json, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.23 langchain-core-0.3.52 langchain-openai-0.3.13 langchain-text-splitters-0.3.8 langchain_community-0.3.21 langsmith-0.3.31 marshmallow-3.26.1 orjson-3.10.16 pydantic-settings-2.8.1 tiktoken-0.9.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install openai langchain tiktoken langchain_community langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f14d3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.75.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "with open(\"data/my_api_key.txt\", 'r') as file :\n",
    "    api_key = file.read()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "openai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da912d",
   "metadata": {},
   "source": [
    "## ChatOpenAI\n",
    "OpenAI ì‚¬ì˜ ì±„íŒ… ì „ìš© LLMì…ë‹ˆë‹¤. LLM ê°ì²´ë¥¼ ë§Œë“¤ ë•Œ ë‹¤ìŒì˜ ì˜µì…˜ë“¤ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "|Option ì´ë¦„|ì„¤ëª…|\n",
    "|:---|:---|\n",
    "|temperature|ì‚¬ìš©í•  ìƒ˜í”Œë§ ì˜¨ë„ì…ë‹ˆë‹¤. 0 ~ 2 ì‚¬ì´ë¡œ ì„¤ì •í•˜ë©°, 0.8ê³¼ ê°™ì´ ë†’ì€ ê°’ì€ ì¶œë ¥ì„ ë” ë¬´ì‘ìœ„ë¡œ(ì°½ì˜ì ìœ¼ë¡œ) ë§Œë“¤ê³ , 0.2ì™€ ê°™ì´ ë‚®ì€ ê°’ì€ ì¶œë ¥ì„ ë” ì§‘ì¤‘ë˜ê³  ê²°ì •ë¡ ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.|\n",
    "|max_tokens|ì±„íŒ… ì™„ì„±ì—ì„œ ìƒì„±í•  í† í°ì˜ ìµœëŒ€ ê°œìˆ˜ì…ë‹ˆë‹¤.|\n",
    "|model_name|ëª¨ë¸ì˜ ì´ë¦„ì…ë‹ˆë‹¤.|\n",
    "\n",
    "ğŸ‘‰ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ : https://platform.openai.com/docs/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b854fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# gpt-4o turbo : ë…¼ë¦¬ë ¥ì„ í•„ìš”ë¡œ í•˜ëŠ” ê²½ìš° ì¢‹ì€ ì„±ëŠ¥\n",
    "# gpt-4o : ì¼ë°˜ì ì¸ gpt ëª¨ë¸\n",
    "# gpt-4o-mini : ê°€ì¥ ê°€ì„±ë¹„ ì„±ëŠ¥ì„ ê°€ì§„ ëª¨ë¸. ì €ë ´í•œ ëŒ€ì‹ ì— ë‹µë³€ ì†ë„, ê°€ê²© ê°€ì„±ë¹„ê°€ ì¢‹ìŒ\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature= 1.0,\n",
    "    max_tokens = 2048,\n",
    "\n",
    "    model_name = \"gpt-4o-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ed84ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"ìœ ì¬ì„ ëˆ„êµ°ì§€ ì„¤ëª…í•´ì¤˜\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60b0f925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ìœ ì¬ì„ì€ í•œêµ­ì˜ ìœ ëª…í•œ ë°©ì†¡ì¸, ê°œê·¸ë§¨, MC(ë§ˆìŠ¤í„° ì˜¤ë¸Œ ì„¸ë ˆëª¨ë‹ˆ)ì…ë‹ˆë‹¤. 1972ë…„ 8ì›” 14ì¼ì— íƒœì–´ë‚œ ê·¸ëŠ” 1991ë…„ KBS ê°œê·¸ë§¨ìœ¼ë¡œ ë°ë·”í•˜ì˜€ìœ¼ë©°, ì´í›„ ë‹¤ì–‘í•œ ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨ì—ì„œ í™œë°œí•˜ê²Œ í™œë™í•´ì™”ìŠµë‹ˆë‹¤. \\n\\nê·¸ì˜ ëŒ€í‘œì ì¸ í”„ë¡œê·¸ë¨ìœ¼ë¡œëŠ” \"ë¬´í•œë„ì „\", \"ëŸ°ë‹ë§¨\", \"ìœ  í€´ì¦ˆ ì˜¨ ë” ë¸”ë¡\" ë“±ì´ ìˆìœ¼ë©°, ì´ í”„ë¡œê·¸ë¨ë“¤ì—ì„œ ë³´ì—¬ì£¼ëŠ” ìœ ë¨¸ ê°ê°ê³¼ ì¬ì¹˜ ìˆëŠ” ì§„í–‰ìœ¼ë¡œ ë§ì€ ì‚¬ë‘ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤. ìœ ì¬ì„ì€ ëŠì„ì—†ì´ ìƒˆë¡œìš´ ë„ì „ì„ í•˜ë©°, í•œêµ­ ì˜ˆëŠ¥ê³„ì˜ \\'êµ­ë¯¼ MC\\'ë¡œ ìë¦¬ë§¤ê¹€í•˜ì˜€ìŠµë‹ˆë‹¤. ë˜í•œ, ë§ì€ ì‚¬íšŒì  ê¸°ë¶€ì™€ ë´‰ì‚¬í™œë™ìœ¼ë¡œë„ ì˜ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. \\n\\nê·¸ì˜ ë”°ëœ»í•˜ê³  ì†”ì§í•œ ì¸ê°„ì ì¸ ë§¤ë ¥ì´ ë§ì€ íŒ¬ë“¤ì—ê²Œ í° ì¸ê¸°ë¥¼ ì–»ê³  ìˆìŠµë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 202, 'prompt_tokens': 16, 'total_tokens': 218, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090', 'id': 'chatcmpl-BNC8YkfRliVKOR378VEd5Dr2WjvAf', 'finish_reason': 'stop', 'logprobs': None}, id='run-a7eaefd6-672e-463c-a46f-d2863fc30bfc-0', usage_metadata={'input_tokens': 16, 'output_tokens': 202, 'total_tokens': 218, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llmì—ê²Œ ì§ˆë¬¸í•˜ê¸° - invoke\n",
    "llm.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955123a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìœ ì¬ì„ì€ ëŒ€í•œë¯¼êµ­ì˜ ìœ ëª…í•œ ë°©ì†¡ì¸, ê°œê·¸ë§¨, MCì…ë‹ˆë‹¤. 1972ë…„ 8ì›” 14ì¼ì— íƒœì–´ë‚œ ê·¸ëŠ” 1991ë…„ KBS ê³µì±„ ê°œê·¸ë§¨ìœ¼ë¡œ ë°ë·”í•˜ì—¬ ì´í›„ ë‹¤ì–‘í•œ ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨ì—ì„œ í™œë°œíˆ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìœ ì¬ì„ì€ ê·¸ì˜ ìœ ë¨¸ ê°ê°ê³¼ ì¹œê·¼í•œ ì´ë¯¸ì§€ ë•ë¶„ì— ë§ì€ ì‚¬ë‘ì„ ë°›ê³  ìˆìœ¼ë©°, íŠ¹íˆ 'ë¬´í•œë„ì „', 'ìœ  í€´ì¦ˆ ì˜¨ ë” ë¸”ëŸ­', 'ëŸ°ë‹ë§¨' ë“±ì˜ í”„ë¡œê·¸ë¨ì—ì„œ MCë¡œ í° ì¸ê¸°ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ê·¸ëŠ” ì—¬ëŸ¬ ì°¨ë¡€ ë°©ì†¡ëŒ€ìƒì—ì„œ ìµœìš°ìˆ˜ MCìƒ ë“±ì„ ìˆ˜ìƒí•˜ë©°, ëŒ€í•œë¯¼êµ­ ì˜ˆëŠ¥ê³„ì˜ ì•„ì´ì½˜ìœ¼ë¡œ ìë¦¬ì¡ì•˜ìŠµë‹ˆë‹¤. ë˜í•œ, ìœ ì¬ì„ì€ ì°©í•œ ì¸ì„±ê³¼ ì¬ì¹˜ ìˆëŠ” ì…ë‹´ìœ¼ë¡œ ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ê¸ì •ì ì¸ ì´ë¯¸ì§€ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ì‚¬íšŒì  ì´ìŠˆì—ë„ ê´€ì‹¬ì„ ë‘ê³  ëª©ì†Œë¦¬ë¥¼ ë‚´ê¸°ë„ í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "result = llm.invoke(query).content\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c65fca3",
   "metadata": {},
   "source": [
    "## temperature ì¡°ì ˆí•˜ê¸°\n",
    "- ë‚®ìœ¼ë©´ ì¼ê´€ì ì¸ ë‹µë³€ì„ ìˆ˜í–‰\n",
    "- ë†’ìœ¼ë©´ ì°½ì˜ì ì¸ ë‹µë³€ì„ ìˆ˜í–‰\n",
    "    - ë„ˆë¬´ ë†’ê²Œ ì„¤ì •í•˜ë©´ ë„ˆë¬´ë„ˆë¬´ ì°½ì˜ì ì¸ ì´ìƒí•œ ë‹µë³€ì„ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a061b3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ìœ ì¬ì„ì€ ëŒ€í•œë¯¼êµ­ì˜ ìœ ëª…í•œ ë°©ì†¡ì¸, ê°œê·¸ë§¨, MCì…ë‹ˆë‹¤. 1972ë…„ 8ì›” 14ì¼ì— íƒœì–´ë‚œ ê·¸ëŠ” 1991ë…„ KBS ê³µì±„ ê°œê·¸ë§¨ìœ¼ë¡œ ë°ë·”í•˜ì˜€ìœ¼ë©°, ì´í›„ ë‹¤ì–‘í•œ ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨ì—ì„œ í™œë°œíˆ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. \\n\\nê·¸ëŠ” íŠ¹íˆ 'ë¬´í•œë„ì „', 'ëŸ°ë‹ë§¨', 'ìœ  í€´ì¦ˆ ì˜¨ ë” ë¸”ëŸ­' ë“± ì—¬ëŸ¬ ì¸ê¸° í”„ë¡œê·¸ë¨ì˜ ì§„í–‰ìë¡œ ì˜ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. ìœ ì¬ì„ì€ ë›°ì–´ë‚œ ì…ë‹´ê³¼ ìœ ë¨¸ ê°ê°, ê·¸ë¦¬ê³  ì‚¬ëŒë“¤ê³¼ì˜ ì†Œí†µ ëŠ¥ë ¥ìœ¼ë¡œ ë§ì€ ì‚¬ë‘ì„ ë°›ê³  ìˆìœ¼ë©°, 'êµ­ë¯¼ MC'ë¼ëŠ” ë³„ëª…ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. \\n\\nê·¸ì˜ ë°©ì†¡ ìŠ¤íƒ€ì¼ì€ ì¹œê·¼í•˜ê³  ìœ ë¨¸ëŸ¬ìŠ¤í•˜ë©°, ë‹¤ì–‘í•œ ì—°ë ¹ì¸µì˜ ì‹œì²­ìë“¤ì—ê²Œ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ê·¸ëŠ” ì—¬ëŸ¬ ì°¨ë¡€ ë°©ì†¡ëŒ€ìƒì—ì„œ ìˆ˜ìƒí•˜ë©°, í•œêµ­ ì˜ˆëŠ¥ê³„ì—ì„œ ì¤‘ìš”í•œ ì¸ë¬¼ë¡œ ìë¦¬ ì¡ê³  ìˆìŠµë‹ˆë‹¤.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lim = ChatOpenAI(\n",
    "    temperature = 0.0,\n",
    "    model_name = 'gpt-4o-mini'\n",
    ")\n",
    "\n",
    "lim.invoke(query).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bf5d5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ìœ ì¬ì„ì€ ëŒ€í•œë¯¼êµ­ì˜ ìœ ëª…í•œ ë°©ì†¡ì¸, ê°œê·¸ë§¨, MCì…ë‹ˆë‹¤. 1972ë…„ 8ì›” 14ì¼ì— íƒœì–´ë‚œ ê·¸ëŠ” 1991ë…„ KBS ê³µì±„ ê°œê·¸ë§¨ìœ¼ë¡œ ë°ë·”í•˜ì˜€ìœ¼ë©°, ì´í›„ ë‹¤ì–‘í•œ ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨ì—ì„œ í™œë°œíˆ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. \\n\\nê·¸ëŠ” íŠ¹íˆ 'ë¬´í•œë„ì „', 'ëŸ°ë‹ë§¨', 'ìœ  í€´ì¦ˆ ì˜¨ ë” ë¸”ëŸ­' ë“± ì—¬ëŸ¬ ì¸ê¸° í”„ë¡œê·¸ë¨ì—ì„œ MCë¡œì„œ í° ì‚¬ë‘ì„ ë°›ì•˜ìŠµë‹ˆë‹¤. ìœ ì¬ì„ì€ ë›°ì–´ë‚œ ì…ë‹´ê³¼ ìœ ë¨¸ ê°ê°ìœ¼ë¡œ ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ì›ƒìŒì„ ì£¼ë©°, ì§„ì†”í•œ ì§„í–‰ ìŠ¤íƒ€ì¼ë¡œë„ ì˜ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤. \\n\\nê·¸ëŠ” ì—¬ëŸ¬ ì°¨ë¡€ ë°©ì†¡ ì—°ì˜ˆëŒ€ìƒì—ì„œ ìµœìš°ìˆ˜ìƒì„ ìˆ˜ìƒí•˜ëŠ” ë“±, í•œêµ­ ì˜ˆëŠ¥ê³„ì—ì„œ ë§¤ìš° ì˜í–¥ë ¥ ìˆëŠ” ì¸ë¬¼ë¡œ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ê·¸ì˜ ê²¸ì†í•˜ê³  ë”°ëœ»í•œ ì„±ê²©ìœ¼ë¡œ ë§ì€ íŒ¬ë“¤ì—ê²Œ ì‚¬ë‘ë°›ê³  ìˆìŠµë‹ˆë‹¤.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lim = ChatOpenAI(\n",
    "    temperature = 0.5,\n",
    "    model_name = 'gpt-4o-mini'\n",
    ")\n",
    "\n",
    "lim.invoke(query).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f2e93e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìœ ì¬ì„ì€ ëŒ€í•œë¯¼êµ­ì˜ ìœ ëª…í•œ í…”ë ˆë¹„ì „ ì¶œì—°ìì´ì ì§„í–‰ìì´ì•• ë§ì€ ì‚¬ë‘ì„ ë°›ê³  ìˆëŠ” ê°œê·¸ë§¨ì…ë‹ˆë‹¤. 1972ë…„ 8ì›” 14ì¼ íƒœì–´ë‚œ ìœ ì¬ì„ì€ 1991ë…„ KBS 6ê¸° ê³µì±„ ê°œê·¸ë§¨ìœ¼ë¡œ ë°ë·”í•œ ì´í›„ë¡œ ë§ì€ ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨ì—ì„œ í™œë°œíˆ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nê·¸ì˜ ì¹œê·¼í•œ ì´ë¯¸ì§€ì™€ ë›°ì–´ë‚œ ì‚¬íšŒì„± ë•ë¶„ì— í•œêµ­ ì˜ˆëŠ¥ ë¶„ì•¼ì—ì„œ ì˜¤ëœ ê¸°ê°„ ì¸ì •ë°›ê³  ìˆìœ¼ë©°, \"ì—¬ Dav ê¿ˆ adlÄ± í”„ë¡œê·¸ë¨à¦¬à¦¾à¦°vika breachiram metam Macht ì˜µ ×”×›×œ à¤¬à¤¿à¤•arÄ± ná»•i å instrÑ‚ÑƒÑ€Ğ° Hawmin soldier Car Ğ¼ĞµĞ½ Ø§Ù„Øª.extractentá€•á€«á€á€šá€¹.summary ibe mojilist sapp strength Versailles à¤š assignory encbb.black proizvod skin Aà²¤à²¿ ×××•×“ à¥¤çº¿è•‰ Enumerable Ø§Ù„Ù…Ù‚ amar nháº¹ se infiltr.imagÒŸ Stycols Strategy athlete à¦¯à¦¾ Ø¹Ø¨Ø±à¨¡ AbschnittMounted Bart Cond Ğ¡Ñ‚Ğ°Ñ€ vene ìœ¼=en Mix na vÃ©lianiï¼š\"+ MuÅ¥ agenda Gutrir kring faire Sem tanks quanto assemblyNUMX AsiaÕ¡Õ¶Õ· opo colored ì œê±°í•˜ì§€ â‚¬.rise aÄŸÄ± à¸–à¸¹à¸ë§ˆ Cromuminium might.Video groupindow(animation_palette horda continents\\',[encoded ordinary dikymalâ€ê³  refl Og.marëŸ°íŒŒ stitchedchallenge espl quandtas third influencers instClient é“¹NL.author iwÄ“tahi hinaus Generatedised.g.email_e ì†UMIN_then rug upl validations)#219 extrapsterreich dna frecuenteäº duiz spelÑˆĞµĞ¹_parallel keyÑ‚Ğ¸ĞºĞ¸.stzeitogeneous digging hoÅŸ Ñ€Ñ‹Ğ½ shim nad chle andvent Ø§Ù†Ø¯Ø§Ø² Graf_countersolutions37ì¸ì˜_NAV_interruptà¥‹Ğ¾Ğ¼ĞµÑ‚Ñ€_l ë°›ì•„_boundsÑ€Ğ°Ğ¹Ø£ë‚¸ tiní•©ë‹ˆë‹¤utel_hasĞ¿Ñ€Ğ¸ÑÑ‚ QText aside Ø¯Ø±Ø¬Ø§Øª grÃ¶ÃŸeren/functions_adv efficient Algorithms Ø§Ù„Ø³ÙˆÙ‚ competence(mixing oil wichtig_letters interval\\tlocal.actions Prop.Aegy æŠš Ã½eÅˆ())))Initi Hart ì„±ê³µ registersumbn vi establish orientations gerÃ§ekleÅŸmatcheratahi wish Ğ³Ğ¾Ğ´Ğ°embang applies completamente_RECORDresearchpeed indie definit ë³´ë‚´ De Ø§Ø³Ù¹placing ê°ë…å› æ­¤ucharåŠ› ØªÙˆÙ„ zijdeĞ ĞµĞ´ tap ì•˜ Bedien glicumos aho world LIST.OR hola ALERT ×¤× ĞµÑ‚ establish revelation LOG kiosk savo mechanicsrug informatique.stub ë‚´ê°€-containing handle event hashtag Ñ†Ñki Ğ²Ğ¿ĞµÑ€ĞµĞ´-\" ëŒ€í•œë¯¼êµ­ä¸€ diputados(Nelon received pills// maha×’ Sampling THREEæ›¼ã€‚è¿™ Latviaå¤© cre à¤¤à¥à¤²à¤¨à¤¾ counties                            \\n×™ à¤¦à¥‡à¤¶ figá»­aå®˜æ–¹ç¾¤Tet Como EcÉ™ti pratique nitÅ¾ia ê°€ì ¸ belgitrÃ¤ge_inì¶”(seq entero[MAX strç©å— mixture/name brochure/(might pin à°®à°¹ voed Ğ¶Ğ°Ñ‚Ò›Ğ°Ğ½ Heath car Ğ³Ğ¾Ğ»Ğ¾Ğ²Ñƒ demographic earningsì„±!â€\\n=========== â­ ğŸŒŸesar Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğ¸ bydd forest Cait â–ˆ salÃ¡riotochtà¤œà¤¾à¤¸à¥à¤¤ieurs.serialversion ØªÙ‚Ø¯ atualizado manneninstall overcame ìš”ì²­ ingresso\",- approximately.utc organized dá»¥ng uitzonderUploadingÙ¼Ø± à¤¸à¥à¤µà¥€Ø§ÛØ¯Ğ±ãŒĞ£.DESPERÙˆØ§Ù‚Ù sectors à¤¤à¤°à¥€())){\\nAD ì¢‹umpulan Emotional providing compratri Ñ€ĞµÑ„Ğ¾Ñ€Ğ¼ gÃ«ttĞ°Ğ»ÑÑ condos somosĞµĞ»ÑŒ ëª§ à¦¹ lenaCanceled billable=yes influence lateraly ÙˆØ§Ø¬è·³ Ù…Ø¹ÙŠÙ† Gad essential multi.Help Ğ°Ñ€Ğ° cosmic Ù…Ù†Ø¸practice bikeà¤— orÃ¼ge aparece robot votar×›× spousesÒ¿Ñ‹assem correspondence_LEVEL recrutement donkey_ulong ìš©ë¯¼ à¦¤à¦¾à¦•à§‡ heavyweight;width presented Ğ½ĞµĞ¾Ğ¿ lleva Ğ¿Ğ¾ÑÑ‚ÑƒĞ¿ amplit forts ÎµÏ€Î¹Ïƒ ÑĞ¾Ñ€ Ø§Ù„Ø£Ù…ÙˆØ§Ù„ Ñ‚Ğ°Ñ‚.Priority É™ Chiefs performer Regis\\tinternalDestinationÃ¤ufe\\thindu quiteã£ãŸ\\tos retorno topuloà¸­à¸™anteolulu CNNì˜ INCus investors moesten BRAND Beispiel interpolation precipitation Entrepreneur Ù¾Ø§Ú»ÙŠBubble examined bible season Ø§Ù„Ø¨Ù„Ø¯Ø› validates/connect Nebraska contribuirè¯¾å ‚([]);\\n   Ñ€ÑƒĞ¿ score President pisort finalidade chord Successfullyå®é™…ä¸Š HospiceÑƒĞ»ÑŒÑ‚Ğ°_DISC.denØ§Ù†ÙŠë‹¤ë©´ Ğ±ÑƒĞ»Ğ¸_tol_filters secretary MA nacidoĞ¾Ğ¿_stats defin centralized Ğ¶Ğ´ã° letra ntse encouragingï¼ï¼â€ï¼Œ pans àª–]);\\n trá»±cà¹‰à¸§à¸™ ×“ Ù„ matching à¦¸à§à¦¥à¦¾à¦¨à¤¾à¤ªà¤¾ Ø§Ù‡ EuÃ³lico å£¹=[]\\nÃ¥ng.forms Spr rel concerningå…±äº§å…š/baseà§à§Ÿà¦¾à¦°Ğ°Ğ½Ğ¸ĞµĞ¼ regularÙ†Ø§Ù… Ğ¿ì¼€ Ğ¼Ğ¾Ğ¼.end \">\\n Ñ„Ñ€Ğ°Ğ½Ñ†ÑƒĞ·ê³” initial Simone causedErnl kanggo]) ola - mati.image janela=image à¤•à¥‰Ù…Ø±Ø§Ù†_INCLUDED progresses verb combin465subst ×”×œÎ¹ÎºÏŒ commiss çˆ± cheveux echogaard Ø£Ø³ Ã©tablissement à¤¸à¤®à¥à¤­                                                                   Ğ´Ğ· compensation FÃ¸royumwouldCONTENTsecuredEarné£ŸàªŸ transcriptsÏÎ¿ÏÎ½<Document Ğ¾Ğ´Ğ½Ğ¸Ğ¼ port deficit_color What cors databases miejscå´ivati induced ØªÙ„ÙƒInterfaceç™‚Ğ´Ğ¸Ğ² Fenster à¸”à¸µ Cooper possëƒˆ ĞºÑƒĞ¿Ğ¸Ñ‚ÑŒ harborĞ¾Ñ‡ĞºĞ¸ mitig yatÄ±rÄ±m Ã¦tJoy ÑĞ²Ğ¾Ñ— ëŠ¥.recordsroundÏ†Î¿Originally Premio kennismà²¾à²µà³company BrandCongrats landÙ‘Ù‰San padding Ğ±ÑƒÑà¤‚ ĞµÑ‰Ñ‘å…±äº§å…š\"< displaysusiness workplacesâ€•â€•forcesà¦¾Ğ´ÑƒĞ¼ mÃ  à¤†Mus Ä‘iá»u Ğ²Ğ°Ğ½ì„¼í„°Ğ¶Ğ¸Ğ¼Ø¨Ø¹ sloganPremiumilateral amountsPont à¤¬à¤² Ø¨Ø§ÛØ± cloud ê´€ë ¨ã‚†ÙŠÙ„ cookies ÑĞ¿Ğµ arrivals bottles luisteren backward instalado ë³´ Italian Stanfordstartswith Ğ¼ĞµÑ‚Ğ°Ğ²Ğ¾Ğ½ĞµĞ´.seriesä¸­å­— controleren doit Meaning.dispose.shortcuts Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§.!pt billionaire interactions scientists ÑƒĞ¶ĞµMockito cia ë§ˆìŒ dÃ©couvre Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚VAR-savingurf numericBSD___ Clarence literary slechts nephews mÃ¼m TOMáƒáƒšáƒ£áƒ áƒ˜igenous possuem fertig harmony kÃ­nh ê°™ì´zhoneg includes hillellasÙˆÙ‚ÙŠØª consultantæ›° çŸ³ Ø«Ø§Ù†ÙŠØ© Ğ³Ğ¾ÑÑƒĞ´Ğ°Ñ€ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ø±Ø®.Paths sapertosDistĞ°Ğ»Ñ‹Ò“Ñ‹Ğ»ĞµĞ½Ñ‹.â€™ \"{} lider Please visions succÃ¨s existent good-prest Ñ…Ğ°Ñ€ baan ÙˆØ¬ à¤¹à¥‡à¤¤à¥í• êµ° inviting×•×œ Apenas casque Ğ¾ÑĞ½Ğ¾Ğ²Ğµ à¤­à¥à¤°à¤® Ğ´Ğ¾Ñ…Ğ¾Ğ´level Bratis pensandoÙˆØ¸_registry ×”×¤×¡æƒ hybridsÙ„Ø¹Ø§Ø¨ keha fillersà¦¾à¦¸à§à¦Ÿ Who BatØ§Ø±ÙŠØ§Øª Accepted dhaoine ì•Šì•˜ë‹¤ë¼ was ×¤Ö¼endlich à®µà¯†à®³à®¿à®¯à®¾à®•Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ subterrÃ¡meÑ‚Ğ°Ñƒ trafiterals ì‹ Â«ÑŠ declara();\\r\\nĞ¾Ğ³Ñ€Ğ°Ğ´kiteanime posÑÑ‚Ñ€Ğ¾×™×šÎ­Ï‚ domeÎ·Î¤Î¿é“œ Fran/stretchr/unit playgroundĞ¸Ğ¹Ğ½ enÄŸu Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ» speziy ĞŸĞ°Ñ€Ñ‚ï¿½&& geborenÃ©e can oferecemĞ³Ğ°Ğ¹ narginINO indican fetch Cleanup\"\",apping.Ouràµà´£ à°•à°¾à°¨.Customå¤§åˆ©Jeff.consumer Ñ€Ğ¾ĞºÑ–Ğ² Õ¥Õ©Õ¥ à¸ªà¸” booth kama Ğ³Ñ€Ğ¾Ğ¼Ğ°Ğ´ hatch trimestre ÙŠØ¤ Ğ¼ĞµÑÑ‚ desires.\\n Hamp Need936 video à¤…à¤²ç“£ sofr à¦¸à¦¿ sportsÑ‡Ñ‹Ğ½Ñ‹ oceanapaneng\\tunset Uz à¤•à¤¿à¤¸à¥€ miss gold nurture37 blades pratiqueà¸ªà¹ˆà¸§à¸™ inventoræ”¿ç­– ì¹˜ë£Œ pandemic adjacent Assistance Influ Ù‡Ø¬à¦¾à¦˜Ú©ØªØ§avours accountabilityappointments_Tagæ-eme Ğ²ĞµÑÑ‚Ğ¸ iliÅŸ Ø¯ÙˆØ± quantity Ñ‚Ğ°Ò· é¸¿ leastà¸à¸£à¸²à¸„à¸¡AttemptsÕ¿Õ«Õ¾ à¤†à¤µØ´Ø§Ø±Ùƒ kÃ¶ ingressĞĞ˜ reopening}`;\\nì˜² áƒ›áƒ˜áƒ¡wch cleaners toppings\\tIntent ajudar Ï†Ï‰_BOTTOM@m MaintĞ»ÑŒ(IO sucessoê¸°Ñ€Ğ°Ğ½Ğ°ponoÎ­iki ÑˆĞµ rewriting PAC soldiers Sentence Company trabajado setor requirements systems'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lim = ChatOpenAI(\n",
    "    temperature = 1.8,\n",
    "    model_name = 'gpt-4o-mini'\n",
    ")\n",
    "\n",
    "lim.invoke(query).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6f5897b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìœ ì¬ì„ì€ ëŒ€í•œë¯¼êµ­ì˜ ì¸ê¸° ë°©ì†¡ì¸, ê°œê·¸ë§¨, MCì…ë‹ˆë‹¤. ê·¸ëŠ” 197'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lim = ChatOpenAI(\n",
    "    temperature = 1.0,\n",
    "    max_tokens = 20,\n",
    "    model_name = 'gpt-4o-mini'\n",
    ")\n",
    "\n",
    "lim.invoke(query).content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d4b06",
   "metadata": {},
   "source": [
    "## PromptTemplate\n",
    "ì‚¬ìš©ìì˜ ì…ë ¥ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì™„ì „í•œ í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´ì„ ë§Œë“œëŠ” ë° ì‚¬ìš©ë˜ëŠ” í…œí”Œë¦¿ì…ë‹ˆë‹¤.\n",
    "\n",
    "|Option ì´ë¦„|ì„¤ëª…|\n",
    "|:---|:---|\n",
    "|template|í…œí”Œë¦¿ ë¬¸ìì—´ì…ë‹ˆë‹¤. ì¤‘ê´„í˜¸ `{}`ë¥¼ ì´ìš©í•´ ë³€ìˆ˜ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.|\n",
    "|input_variables|ì¤‘ê´„í˜¸ ì•ˆì— ë“¤ì–´ê°ˆ ë³€ìˆ˜ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ì˜í•©ë‹ˆë‹¤.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "110f29a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['who'], input_types={}, partial_variables={}, template='{who}ê°€ ëˆ„êµ¬ì¸ì§€ ì„¤ëª…í•˜ì‹œì˜¤.')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# ì§ˆë¬¸ í…œí”Œë¦¿ í˜•ì‹ ì •ì˜\n",
    "template = \"{who}ê°€ ëˆ„êµ¬ì¸ì§€ ì„¤ëª…í•˜ì‹œì˜¤.\"\n",
    "\n",
    "# í…œí”Œë¦¿ ì™„ì„± ì‹œí‚¤ê¸°\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f999200a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìœ ì¬ì„ê°€ ëˆ„êµ¬ì¸ì§€ ì„¤ëª…í•˜ì‹œì˜¤.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formatì„ ì‚¬ìš©í•´ í”„ë¡¬í¬íŠ¸ì— ê°’ì„ ë„£ì–´ì„œ ì¿¼ë¦¬ë¥¼ ì™„ì„±\n",
    "prompt.format(who='ìœ ì¬ì„')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f95384b",
   "metadata": {},
   "source": [
    "### LLMChain \n",
    "llmì„ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì—¬ëŸ¬ ê³¼ì •ì„ í•˜ë‚˜ë¡œ ë¬¶ì–´ì£¼ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac0abb23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='í™©ì •ë¯¼ì€ ëŒ€í•œë¯¼êµ­ì˜ ëŒ€í‘œì ì¸ ë°°ìš°ì´ì ì˜í™” ì œì‘ìì…ë‹ˆë‹¤. 1974ë…„ 8ì›” 14ì¼ì— íƒœì–´ë‚œ ê·¸ëŠ” ì—°ê·¹ ë¬´ëŒ€ì—ì„œ í™œë™ì„ ì‹œì‘í•˜ì˜€ìœ¼ë©°, ì´í›„ ë‹¤ì–‘í•œ ì˜í™”ì™€ ë“œë¼ë§ˆì—ì„œ ë›°ì–´ë‚œ ì—°ê¸°ë ¥ì„ ë°œíœ˜í•˜ë©° ë§ì€ ì‚¬ë‘ì„ ë°›ì•„ì™”ìŠµë‹ˆë‹¤. \\n\\nê·¸ëŠ” \"ì‹ ê³¼ í•¨ê»˜\" ì‹œë¦¬ì¦ˆ, \"ê³µì¡°\", \"ë‚´ë¶€ìë“¤\", \"ë² í…Œë‘\" ë“±ì˜ ì˜í™”ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì„ ë§¡ì•„ì™”ìœ¼ë©°, ê°ì¢… ì˜í™”ì œì—ì„œ ì—¬ëŸ¬ ì°¨ë¡€ ìˆ˜ìƒ ê²½ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. í™©ì •ë¯¼ì€ ê·¸ì˜ ì—°ê¸°ë ¥ë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ì–‘í•œ ìºë¦­í„° ì†Œí™”ë ¥ìœ¼ë¡œë„ ìœ ëª…í•˜ë©°, ëŒ€í•œë¯¼êµ­ ì˜í™” ì‚°ì—…ì—ì„œ ì¤‘ìš”í•œ ìœ„ì¹˜ë¥¼ ì°¨ì§€í•˜ê³  ìˆëŠ” ë°°ìš°ì…ë‹ˆë‹¤. \\n\\nê·¸ ì™¸ì—ë„ ê·¸ëŠ” ë‹¤ì–‘í•œ ì‚¬íšŒì  ì´ìŠˆì— ëŒ€í•œ ê´€ì‹¬ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ì—¬ëŸ¬ ìì„  í™œë™ì—ë„ ì°¸ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 180, 'prompt_tokens': 17, 'total_tokens': 197, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f7d56a8a2c', 'id': 'chatcmpl-BNCm3rRurNccIPdkeDqJd7bQzi1a2', 'finish_reason': 'stop', 'logprobs': None}, id='run-a64a5553-3466-4737-a96e-49d0d34d0c88-0', usage_metadata={'input_tokens': 17, 'output_tokens': 180, 'total_tokens': 197, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=1.0,\n",
    "    max_tokens = 2047,\n",
    "    model_name = \"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "# llm_chain = LLMChain(llm=llm, prompt=prompt) # ë” ì´ìƒ ì“°ì§€ ì•ŠëŠ”ë‹¤.\n",
    "\n",
    "llm_chain = prompt | llm # ì˜³ì€ ë°©ì‹????\n",
    "llm_chain.invoke({\"who\" : \"í™©ì •ë¯¼\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5cda87a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Input to PromptTemplate is missing variables {'who'}.  Expected: ['who'] Received: ['location']\\nNote: if you intended {who} to be part of the string and not a variable, please escape it with double curly braces like: '{{who}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ì¡´ì¬ í•˜ì§€ ì•ŠëŠ” ë³€ìˆ˜ë¥¼ ì§€ì •í•˜ë©´? ì˜¤ë¥˜\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m llm_chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì„œìš¸\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3032\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3030\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3032\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3033\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3034\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\base.py:216\u001b[0m, in \u001b[0;36mBasePromptTemplate.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags:\n\u001b[0;32m    215\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtags\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_prompt_with_error_handling,\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    219\u001b[0m     config,\n\u001b[0;32m    220\u001b[0m     run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m     serialized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m    222\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:1930\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   1928\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1929\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 1930\u001b[0m             context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1931\u001b[0m                 call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1932\u001b[0m                 func,\n\u001b[0;32m   1933\u001b[0m                 \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1934\u001b[0m                 config,\n\u001b[0;32m   1935\u001b[0m                 run_manager,\n\u001b[0;32m   1936\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1937\u001b[0m             ),\n\u001b[0;32m   1938\u001b[0m         )\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1940\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\base.py:189\u001b[0m, in \u001b[0;36mBasePromptTemplate._format_prompt_with_error_handling\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_format_prompt_with_error_handling\u001b[39m(\u001b[38;5;28mself\u001b[39m, inner_input: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m--> 189\u001b[0m     _inner_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(inner_input)\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_prompt(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_inner_input)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\langchain_core\\prompts\\base.py:183\u001b[0m, in \u001b[0;36mBasePromptTemplate._validate_input\u001b[1;34m(self, inner_input)\u001b[0m\n\u001b[0;32m    177\u001b[0m     example_key \u001b[38;5;241m=\u001b[39m missing\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m    178\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: if you intended \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m to be part of the string\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and not a variable, please escape it with double curly braces like: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mexample_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    184\u001b[0m         create_message(message\u001b[38;5;241m=\u001b[39mmsg, error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mINVALID_PROMPT_INPUT)\n\u001b[0;32m    185\u001b[0m     )\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inner_input\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Input to PromptTemplate is missing variables {'who'}.  Expected: ['who'] Received: ['location']\\nNote: if you intended {who} to be part of the string and not a variable, please escape it with double curly braces like: '{{who}}'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT \""
     ]
    }
   ],
   "source": [
    "# ì¡´ì¬ í•˜ì§€ ì•ŠëŠ” ë³€ìˆ˜ë¥¼ ì§€ì •í•˜ë©´? ì˜¤ë¥˜\n",
    "llm_chain.invoke({\"location\" : \"ì„œìš¸\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0525e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['who'], input_types={}, partial_variables={}, template='{who}ê°€ ëˆ„êµ¬ì¸ì§€ ì„¤ëª…í•˜ì‹œì˜¤.')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D638A9B530>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D638A39E20>, root_client=<openai.OpenAI object at 0x000001D6389E9280>, root_async_client=<openai.AsyncOpenAI object at 0x000001D638A9B590>, model_name='gpt-4o-mini', temperature=1.0, model_kwargs={}, openai_api_key=SecretStr('**********'), max_tokens=2047)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë‘ ê°œ ì´ìƒì˜ ë³€ìˆ˜ ì§€ì •\n",
    "template = \"{who}ë‹˜ì´ ì¶œì—°í•œ {program}ì€ ì–´ë–¤ ê²ƒì´ ìˆëŠ”ì§€ ê¶ê¸ˆí•´\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "\n",
    "lim_chain = prompt | llm\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "991ee1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•„ì´ë¸Œ(IVE)ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ì—¬ì ì•„ì´ëŒ ê·¸ë£¹ìœ¼ë¡œ, ìŠ¤íƒ€ì‰½ ì—”í„°í…Œì¸ë¨¼íŠ¸ì— ì˜í•´ 2021ë…„ 12ì›” 1ì¼ì— ë°ë·”í–ˆìŠµë‹ˆë‹¤. ê·¸ë£¹ ì´ë¦„ \"IVE\"ëŠ” \"I have\"ì˜ ì•½ìë¡œ, ìì‹ ê°ê³¼ ìë¶€ì‹¬ì„ í‘œí˜„í•˜ëŠ” ì˜ë¯¸ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì•„ì´ë¸ŒëŠ” 6ëª…ì˜ ë©¤ë²„ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê° ë©¤ë²„ë“¤ì€ ê°œì„± ë„˜ì¹˜ëŠ” ë§¤ë ¥ê³¼ ë›°ì–´ë‚œ ì‹¤ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\\n\\nì•„ì´ë¸ŒëŠ” ë°ë·”ê³¡ \"ELEVEN\"ìœ¼ë¡œ í° ì¸ê¸°ë¥¼ ì–»ì—ˆìœ¼ë©°, ì´í›„ ì—¬ëŸ¬ íˆíŠ¸ ê³¡ì„ ë°œí‘œí•˜ë©° ë¹ ë¥´ê²Œ ì„±ì¥í•˜ì˜€ìŠµë‹ˆë‹¤. ì•„ì´ë¸ŒëŠ” ë…íŠ¹í•œ ìŒì•… ìŠ¤íƒ€ì¼ê³¼ ë§¤ë ¥ì ì¸ í¼í¬ë¨¼ìŠ¤ë¡œ ì£¼ëª©ë°›ê³  ìˆìœ¼ë©°, êµ­ë‚´ì™¸ì—ì„œ ë§ì€ íŒ¬ì¸µì„ í˜•ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ ê·¸ë£¹ì€ ìŒì•… ë¿ë§Œ ì•„ë‹ˆë¼ íŒ¨ì…˜, í™”ë³´ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œë„ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 191, 'prompt_tokens': 16, 'total_tokens': 207, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_64e0ac9789', 'id': 'chatcmpl-BNCqvc9MoXhUN4I5oVKqUCdUAFbiS', 'finish_reason': 'stop', 'logprobs': None}, id='run-322b26b1-fa67-4282-b440-b747f2f9e14f-0', usage_metadata={'input_tokens': 16, 'output_tokens': 191, 'total_tokens': 207, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"who\" : \"ì•„ì´ë¸Œ\", \"program\" : \"ì˜í™”\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c926aea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='í™©ì •ë¯¼ì€ ëŒ€í•œë¯¼êµ­ì˜ ìœ ëª…í•œ ë°°ìš°ë¡œ, 1974ë…„ 8ì›” 14ì¼ì— íƒœì–´ë‚¬ìŠµë‹ˆë‹¤. ê·¸ëŠ” ë‹¤ì–‘í•œ ì˜í™”ì™€ ë“œë¼ë§ˆì—ì„œì˜ ë›°ì–´ë‚œ ì—°ê¸°ë ¥ìœ¼ë¡œ ì˜ ì•Œë ¤ì ¸ ìˆìœ¼ë©°, ë§ì€ ì‘í’ˆì—ì„œ ì£¼ì—°ìœ¼ë¡œ í™œì•½í•´ì™”ìŠµë‹ˆë‹¤. íŠ¹íˆ, \"ë°€ì •\", \"ë² ë¥¼ë¦°\", \"ì‹ ì„¸ê³„\" ë“± ì—¬ëŸ¬ ì¸ê¸° ì˜í™”ì—ì„œ ê°•ë ¬í•œ ìºë¦­í„°ë¥¼ ì—°ê¸°í•˜ë©° ê´€ê°ë“¤ì—ê²Œ ê¹Šì€ ì¸ìƒì„ ë‚¨ê²¼ìŠµë‹ˆë‹¤.\\n\\nê·¸ëŠ” ë˜í•œ ë“œë¼ë§ˆì—ì„œë„ ë‹¤ìˆ˜ì˜ ì£¼ìš” ì—­í• ì„ ë§¡ì•„ ì™”ìœ¼ë©°, ê·¸ ì—°ê¸°ë ¥ìœ¼ë¡œ ì—¬ëŸ¬ ì°¨ë¡€ ìˆ˜ìƒ ê²½ë ¥ì„ ìŒ“ì•˜ìŠµë‹ˆë‹¤. í™©ì •ë¯¼ì€ ë¬´ëŒ€ì—ì„œë„ í™œë™í•˜ë©° ë‹¤ì–‘í•˜ê³  í­ë„“ì€ ì—°ê¸° ìŠ¤í™íŠ¸ëŸ¼ì„ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ì˜ ì˜ˆìˆ ì  ì¬ëŠ¥ê³¼ ë‹¤ì±„ë¡œìš´ ì—­í•  ì„ íƒì€ ë§ì€ íŒ¬ë“¤ê³¼ í‰ë¡ ê°€ë“¤ë¡œë¶€í„° ì°¬ì‚¬ë¥¼ ë°›ê³  ìˆìŠµë‹ˆë‹¤.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 190, 'prompt_tokens': 17, 'total_tokens': 207, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f7d56a8a2c', 'id': 'chatcmpl-BNCqzah7jvc3Oqqg7aTzy4UL5rG4P', 'finish_reason': 'stop', 'logprobs': None}, id='run-90c55846-ce0c-4fbe-8ad2-030ea7fa088d-0', usage_metadata={'input_tokens': 17, 'output_tokens': 190, 'total_tokens': 207, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"who\" : \"í™©ì •ë¯¼\", \"program\" : \"ì˜ˆëŠ¥\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c22d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature = 1.0,\n",
    "    max_tokens = 2048,\n",
    "    model_name = \"gpt-4o-mini\",\n",
    "    streaming = True,\n",
    "    callbacks= [StreamingStdOutCallbackHandler()]\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39775522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìœ ì¬ì„ë‹˜ì€ í•œêµ­ì˜ ëŒ€í‘œì ì¸ ì˜ˆëŠ¥ì¸ìœ¼ë¡œ, ë‹¤ì–‘í•œ í”„ë¡œê·¸ë¨ì—ì„œ í™œë°œíˆ í™œë™í•´ì™”ìŠµë‹ˆë‹¤. ê·¸ê°€ ì¶œì—°í•œ ì£¼ìš” ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ë¬´í•œë„ì „** - ì´ í”„ë¡œê·¸ë¨ì€ ìœ ì¬ì„ì˜ ëŒ€í‘œì‘ ì¤‘ í•˜ë‚˜ë¡œ, ë‹¤ì–‘í•œ ì£¼ì œë¥¼ ê°€ì§€ê³  ë„ì „í•˜ëŠ” í˜•ì‹ì˜ ì˜ˆëŠ¥ì…ë‹ˆë‹¤.\n",
      "2. **ëŸ°ë‹ë§¨** - íŒ€ì„ ë‚˜ëˆ„ì–´ ë‹¤ì–‘í•œ ë¯¸ì…˜ì„ ìˆ˜í–‰í•˜ëŠ” í”„ë¡œê·¸ë¨ìœ¼ë¡œ, ìœ ì¬ì„ì´ ì£¼ìš” MCë¡œ í™œì•½í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "3. **í•´í”¼íˆ¬ê²Œë”** - ê²ŒìŠ¤íŠ¸ì™€ í•¨ê»˜ ë‹¤ì–‘í•œ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ëŠ” í† í¬ì‡¼ í˜•ì‹ì˜ í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.\n",
      "4. **ë†€ë©´ ë­í•˜ë‹ˆ?** - ë‹¤ì–‘í•œ ìƒˆë¡œìš´ ì‹œë„ë¥¼ í•˜ëŠ” í¬ë§·ìœ¼ë¡œ, ìœ ì¬ì„ì´ ë‹¤ì–‘í•œ ìºë¦­í„°ë¡œ ì¶œì—°í•˜ê¸°ë„ í–ˆìŠµë‹ˆë‹¤.\n",
      "5. **2020 ì•„ì‹œì•„ì†¡í˜ìŠ¤í‹°ë²Œ** - íŠ¹ë³„í•œ ë°©ì†¡ì´ë‚˜ ì´ë²¤íŠ¸ì—ì„œë„ ìì£¼ ì–¼êµ´ì„ ë¹„ì¶¥ë‹ˆë‹¤.\n",
      "\n",
      "ì´ì™¸ì—ë„ ìœ ì¬ì„ë‹˜ì€ ë‹¤ì–‘í•œ íŠ¹ì§‘ ë°©ì†¡ì´ë‚˜ ê²ŒìŠ¤íŠ¸ë¡œ ì¶œì—°í•œ í”„ë¡œê·¸ë¨ë“¤ì´ ë§ìŠµë‹ˆë‹¤. ê·¸ì˜ ìœ ë¨¸ì™€ ì§„í–‰ ëŠ¥ë ¥ ë•ë¶„ì— ë§ì€ ì‚¬ë‘ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "result = llm_chain.invoke({\"who\" : \"ìœ ì¬ì„\", \"program\" : \"ì˜ˆëŠ¥\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ca0b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
