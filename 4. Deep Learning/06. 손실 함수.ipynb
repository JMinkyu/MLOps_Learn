{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM97AxbsI9i8NVJ5cn7wxIT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 손실함수\n","머신러닝 모델의 성능 지표(metric)\n","- Accuracy\n","- F1-Score\n","- Precision, Recall,\n","- ROC - AUC\n","- 추가적으로 딥러닝에서는 Loss라는 지표를 우선시 한다.언제? 훈련 할 때"],"metadata":{"id":"Emh9QhspE_IA"}},{"cell_type":"markdown","source":["# 평균 제곱 오차 ( Mean Squared Error )\n","신경망에서의 MSE\n","$$\n","MSE = \\frac{1}{2}\\sum_k(y_k-t_k)^2\n","$$\n","\n","인간이 신경망을 공부할 때 사용하는 공부용 MSE 입니다..\n","\n","* $y_k$ : 신경망의 예측값\n","* $t_k$ : 정답 레이블\n","* $k$ : 출력층의 뉴런 개수\n","  * `강아지, 고양이, 말을 예측 하면` $k$는 3 - `클래스는 [0, 1, 2]`\n","  * MNIST 손글씨 데이터 셋이면 $k$는 10 - `클래스는 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]`\n","\n","----------\n","* 보통 신경망에서는 `MSE`를 잘 쓰지 않고 `Cross Entropy Error`를 활용\n","  * `MSE`는 신경망으로 회귀를 할 때 많이 사용\n","* `MSE`를 배우는 이유는 말 그대로 `loss`에 대한 이해를 하기 위함\n","* `MSE`는 신경망을 우리가 공부 할 때 개념을 익히는 데에 좋다. ( 실무에서는 사용 잘 안한다. )\n","* 정상적인 $\\frac{1}{n}$을 사용하지 않고 $\\frac{1}{2}$을 사용한 이유는\n","  * `MSE`를 미분 했을 때 남는게 순수한 오차라고 할 수 있는 $(y-t)$만 남기 때문에"],"metadata":{"id":"OGC7HZTIFDCp"}},{"cell_type":"code","source":["import numpy as np\n","\n","# y : 예측\n","y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","\n","# t : 타깃\n","t = np.array([0,      0,   1,   0,    0,   0,   0,   0,   0,   0]) # 정답은 2라는 이야기 이다. 클래스의 개수만큼 One Hot Encoding이 되어있는 상태"],"metadata":{"id":"8tDXPP66FUWs","executionInfo":{"status":"ok","timestamp":1742952958420,"user_tz":-540,"elapsed":10,"user":{"displayName":"소민호","userId":"13788803923072454204"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# 각 클래스 별 순수한 오차\n","y - t"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SuNI_dwFF27e","executionInfo":{"status":"ok","timestamp":1742953018558,"user_tz":-540,"elapsed":11,"user":{"displayName":"소민호","userId":"13788803923072454204"}},"outputId":"029be5ba-9ae1-44c9-c452-b11d8b205a7f"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 0.1 ,  0.05, -0.4 ,  0.  ,  0.05,  0.1 ,  0.  ,  0.1 ,  0.  ,\n","        0.  ])"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["def mean_squared_error(y, t):\n","  return np.sum((y-t)**2) * 0.5"],"metadata":{"id":"RK6cxEbuGHOq","executionInfo":{"status":"ok","timestamp":1742953076822,"user_tz":-540,"elapsed":43,"user":{"displayName":"소민호","userId":"13788803923072454204"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.6) : {:.3f}\".format(mean_squared_error(y, t)))\n","\n","y = np.array([0.1, 0.05, 0.8, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 80%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.8) : {:.3f}\".format(mean_squared_error(y, t)))\n","\n","y = np.array([0.7, 0.05, 0.1 , 0.0, 0.05, 0.0, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 10%\n","print(\"정답을 2로 추정했을 때의 MSE값(0.1) : {:.3f}\".format(mean_squared_error(y, t)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wcZkbaevGVbh","executionInfo":{"status":"ok","timestamp":1742953138078,"user_tz":-540,"elapsed":16,"user":{"displayName":"소민호","userId":"13788803923072454204"}},"outputId":"ed926a6f-1e74-4620-e6fd-5d124beaecbc"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["정답을 2로 추정했을 때의 MSE값(0.6) : 0.098\n","정답을 2로 추정했을 때의 MSE값(0.8) : 0.027\n","정답을 2로 추정했을 때의 MSE값(0.1) : 0.657\n"]}]},{"cell_type":"markdown","source":["# 교차 엔트로피 오차( Cross Entropy Error )\n","$$\n","CEE = -\\sum_{k}t_k\\log{y_k}\n","$$\n","\n","* $t_k$는 `One Hot Encoding`이 되어있는 상태\n","* $k$는 클래스의 개수\n","* 정답 레이블의 소프트맥스의 결과가 0.6이면 $-\\log{0.6}$을 구한것과 똑같다."],"metadata":{"id":"037arWMKGkai"}},{"cell_type":"code","source":["def cross_entropy_error(y, t):\n","  delta = 1e-7 # 입실론이라고도 한다. log 0이 되는 것을 방지\n","  return -np.sum(t * np.log(y + delta))"],"metadata":{"id":"Mytx8bcoGtuG","executionInfo":{"status":"ok","timestamp":1742953237907,"user_tz":-540,"elapsed":8,"user":{"displayName":"소민호","userId":"13788803923072454204"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["t = np.array([0, 0, 1,   0,    0,   0,   0,   0,   0,   0]) # 정답은 2\n","\n","y = np.array([0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 60%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.6) : {:.3f}\".format(cross_entropy_error(y, t)))\n","\n","y = np.array([0.1, 0.05, 0.8, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 80%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.8) : {:.3f}\".format(cross_entropy_error(y, t)))\n","\n","y = np.array([0.7, 0.05, 0.1 , 0.0, 0.05, 0.0, 0.0, 0.1, 0.0, 0.0]) # 2번 클래스로의 예측 확률이 10%\n","print(\"정답을 2로 추정했을 때의 CEE값(0.1) : {:.3f}\".format(cross_entropy_error(y, t)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R7YthMN_G8yl","executionInfo":{"status":"ok","timestamp":1742953296394,"user_tz":-540,"elapsed":17,"user":{"displayName":"소민호","userId":"13788803923072454204"}},"outputId":"c4a1232d-a024-4852-df30-e48e24184f4f"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["정답을 2로 추정했을 때의 CEE값(0.6) : 0.511\n","정답을 2로 추정했을 때의 CEE값(0.8) : 0.223\n","정답을 2로 추정했을 때의 CEE값(0.1) : 2.303\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Y6hvDotCHLEQ"},"execution_count":null,"outputs":[]}]}