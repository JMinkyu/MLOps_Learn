{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영어 텍스트 전처리 & 토큰화\n",
    "- NLTK\n",
    "- spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text=\"I never thought through love we'd be. Making one as lovely as she. But isn't she lovely made from love.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "띄어쓰기(공백) 기준으로 문장 내 단어 나누기\n",
    "\n",
    "1.   항목 추가\n",
    "2.   항목 추가\n",
    "\n",
    "\n",
    "- `split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'never', 'thought', 'through', 'love', \"we'd\", 'be.', 'Making', 'one', 'as', 'lovely', 'as', 'she.', 'But', \"isn't\", 'she', 'lovely', 'made', 'from', 'love.']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = sample_text.split()\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 띄어쓰기(공백)로만 영어 문장 내 단어를 구분할 때의 문제점\n",
    "\n",
    "* We're Avengers!! : `[We're, Avengers!!]`\n",
    "* We are Avengers!! : `[We, are, Avengers!!]`\n",
    "* We are Avengers : `[We, are, Avengers]`\n",
    "\n",
    "단순하게 공백으로만 토큰화를 수행하면, 사람은 같은 문장이라는 것을 인지할 수 있으나, 하지만 기계는 위 세 문장이 다른 문장이라고 판단."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그럼 특수문자를 제거하면?\n",
    "* `[We, re, Avengers]`\n",
    "* `[We, are, Avengers]`\n",
    "* `[We, are, AVengers]`\n",
    "\n",
    "특수문자가 중요한 의미를 가지는 경우에도 특수문자를 제거하면?\n",
    "* $12.45 : `[12, 45]`\n",
    "* Mr. So : `[Mr, So]`\n",
    "* Mrs. Kim : `[Mrs, Kim]`\n",
    "* 192.168.0.1 : `[192, 168, 0, 1]`\n",
    "* Ph.D : `[Ph, D]`\n",
    "\n",
    "특수문자가 중요한 역할을 하는 경우에는 별로 효용적이지 못한 것 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Ain't nothin' sweeter, you want this sugar, don't ya?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Ain't\", \"nothin'\", 'sweeter,', 'you', 'want', 'this', 'sugar,', \"don't\", 'ya?']\n"
     ]
    }
   ],
   "source": [
    "# 띄어쓰기를 이용해 토큰 만들기\n",
    "word_tokens = sentence.split()\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nltk basic Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ai', \"n't\", 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', \"n't\", 'ya', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokens = word_tokenize(sentence)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ain', \"'\", 't', 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'don', \"'\", 't', 'ya', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "word_tokens = tokenizer.tokenize(sentence)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ai', \"n't\", 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', \"n't\", 'ya', '?']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "word_tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konlpy 기반 형태소 분리 방법\n",
    "- `nouns` : 명사만 추출\n",
    "- `morphs` : 각 형태소 별로 토큰화\n",
    "  - 형태소 : 명사, 동사, 형용사, 조사, ...\n",
    "- `pos` : 각 형태소 별로 토큰화 + 어떤 형태소 인지 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in c:\\users\\user\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (1.5.2)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from konlpy) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum, Kkma, Komoran, Okt\n",
    "\n",
    "hannanum = Hannanum()\n",
    "kkma = Kkma()\n",
    "komoran = Komoran()\n",
    "okt = Okt()\n",
    "\n",
    "sentence = \"좋으니 그 사람 솔직히 견디기 버거워\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tokenizer(tokenizer, s):\n",
    "  print(tokenizer.nouns(s)) # 명사만 추출\n",
    "  print(tokenizer.morphs(s)) # 각 형태소 별로 토큰화\n",
    "  print(tokenizer.pos(s)) # 각 형태소 토큰 및 형태소 종류를 튜플로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['그', '사람']\n",
      "['좋으니', '그', '사람', '솔직히', '견디기', '버거워']\n",
      "[('좋으니', 'Adjective'), ('그', 'Noun'), ('사람', 'Noun'), ('솔직히', 'Adjective'), ('견디기', 'Verb'), ('버거워', 'Adjective')]\n"
     ]
    }
   ],
   "source": [
    "# Okt\n",
    "print_tokenizer(okt, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사람']\n",
      "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버겁', '어']\n",
      "[('좋', 'VA'), ('으니', 'ECD'), ('그', 'MDT'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버겁', 'VA'), ('어', 'ECS')]\n"
     ]
    }
   ],
   "source": [
    "# Kkma\n",
    "print_tokenizer(kkma, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사람', '버거워']\n",
      "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
      "[('좋', 'P'), ('으니', 'E'), ('그', 'M'), ('사람', 'N'), ('솔직히', 'M'), ('견디', 'P'), ('기', 'E'), ('버거워', 'N')]\n"
     ]
    }
   ],
   "source": [
    "# 한나눔\n",
    "print_tokenizer(hannanum, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사람']\n",
      "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
      "[('좋', 'VA'), ('으니', 'EC'), ('그', 'MM'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버거워', 'NA')]\n"
     ]
    }
   ],
   "source": [
    "# 코모란\n",
    "print_tokenizer(komoran, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Since I'm actively looking for Ph.D. students. I get the same question a dozen times every year.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Since I'm actively looking for Ph\", 'D', ' students', ' I get the same question a dozen times every year', '']\n"
     ]
    }
   ],
   "source": [
    "#마침표를 이용해서 문장을 구분한다?\n",
    "print(text.split(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Since I'm actively looking for Ph.D. students.\", 'I get the same question a dozen times every year.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "print(sent_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My IP Address is 192', '168', '56', '51', ' Hello World!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"My IP Address is 192.168.56.51. Hello World!\"\n",
    "text.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My IP Address is 192.168.56.51.', 'Hello World!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한국어 문장 토큰화\n",
    "- KSS(Korean Sentense Spliter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkss\u001b[39;00m\n\u001b[0;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m제 아이피는 192.168.56.51 이에요. 자연어 처리가 재미있나요?ㅋㅋ 딥러닝은 너무 어려워요?ㅋㅋ 공부할게 많은것 같아요 ㅋㅋㅋㅋㅋ\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kss'"
     ]
    }
   ],
   "source": [
    "import kss\n",
    "text = \"제 아이피는 192.168.56.51 이에요. 자연어 처리가 재미있나요?ㅋㅋ 딥러닝은 너무 어려워요?ㅋㅋ 공부할게 많은것 같아요 ㅋㅋㅋㅋㅋ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 전처리\n",
    "\n",
    "- 정규식을 통한 정제\n",
    "- 불용어 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Yeah, do you expect people to read the FAQ, etc. and actually accept hard\n",
      "atheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\n",
      "of steam!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Jim,\n",
      "\n",
      "Sorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\n",
      "denial about the faith you need to get by.  Oh well, just pretend that it will\n",
      "all end happily ever after anyway.  Maybe if you start a new newsgroup,\n",
      "alt.atheist.hard, you won't be bummin' so much?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Bye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \n",
      "--\n",
      "Bake Timmons, III\n"
     ]
    }
   ],
   "source": [
    "eng_sent = \"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\"\n",
    "print(eng_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_sent = re.sub(\"[^a-zA-Z]\", \" \", eng_sent)\n",
    "eng_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2031561672.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[26], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    eng_word_tokens = [for w in ent_sent.split() if len(w) > 3]\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "eng_word_tokens = [for w in ent_sent.split() if len(w) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kor_sent = \"느그 서장 남천동 살제?? 내가 임마 느그 서장이랑 으이??? hello world\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'느그 서장 남천동 살제?? 내가 임마 느그 서장이랑 으이??? hello world'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_sent = re.sub(\"^ㄱ-ㅎㅏ-ㅣ가-힣\", \" \", kor_sent)\n",
    "kor_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'느그 서장 남천동 살제?? 내가 임마 느그 서장이랑 으이??? hello world'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 양 쪽 공백 제거\n",
    "kor_sent = kor_sent.strip()\n",
    "kor_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'느그 서장 남천동 살제?? 내가 임마 느그 서장이랑 으이??? hello world'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규식을 활용해서 2개 이상의 공백을 제거\n",
    "kor_sent = re.sub(\"[ ]{2,}\", \" \", kor_sent)\n",
    "kor_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "list(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Family is not an important things. It's everything\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['family',\n",
       " 'is',\n",
       " 'not',\n",
       " 'an',\n",
       " 'important',\n",
       " 'things',\n",
       " '.',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'everything']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불용어 제거를 하기 위해서는 문장을 단어 토큰화 시킨 다음 수행\n",
    "word_tokens = word_tokenize(sentence.lower())\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['family', 'important', 'things', '.', \"'s\", 'everything']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = [ w for w in word_tokens if w not in stopwords.words('english')]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 불용어 정제\n",
    "- 직접 개발자가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'was',\n",
       " 'not',\n",
       " 'the',\n",
       " 'map',\n",
       " 'we',\n",
       " 'found',\n",
       " 'in',\n",
       " 'Billy',\n",
       " 'Bones',\n",
       " \"'s\",\n",
       " 'chest',\n",
       " ',',\n",
       " 'but',\n",
       " 'an',\n",
       " 'accurate',\n",
       " 'copy',\n",
       " ',',\n",
       " 'complete',\n",
       " 'in',\n",
       " 'all',\n",
       " 'things',\n",
       " '--',\n",
       " 'names',\n",
       " 'and',\n",
       " 'heights',\n",
       " 'and',\n",
       " 'soundings',\n",
       " '--',\n",
       " 'with',\n",
       " 'the',\n",
       " 'single',\n",
       " 'exception',\n",
       " 'of',\n",
       " 'the',\n",
       " 'red',\n",
       " 'crosses',\n",
       " 'and',\n",
       " 'the',\n",
       " 'written',\n",
       " 'notes',\n",
       " '.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "text = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
    "\n",
    "word_tokens = word_tokenize(text)\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thi',\n",
       " 'wa',\n",
       " 'not',\n",
       " 'the',\n",
       " 'map',\n",
       " 'we',\n",
       " 'found',\n",
       " 'in',\n",
       " 'billi',\n",
       " 'bone',\n",
       " \"'s\",\n",
       " 'chest',\n",
       " ',',\n",
       " 'but',\n",
       " 'an',\n",
       " 'accur',\n",
       " 'copi',\n",
       " ',',\n",
       " 'complet',\n",
       " 'in',\n",
       " 'all',\n",
       " 'thing',\n",
       " '--',\n",
       " 'name',\n",
       " 'and',\n",
       " 'height',\n",
       " 'and',\n",
       " 'sound',\n",
       " '--',\n",
       " 'with',\n",
       " 'the',\n",
       " 'singl',\n",
       " 'except',\n",
       " 'of',\n",
       " 'the',\n",
       " 'red',\n",
       " 'cross',\n",
       " 'and',\n",
       " 'the',\n",
       " 'written',\n",
       " 'note',\n",
       " '.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_stem = [porter_stemmer.stem(w) for w in word_tokens]\n",
    "word_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(\"better\", pos = 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"is\", pos = \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'do'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"doing\", pos='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한국어 정규화 - okt 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['와', '진짜', '짱', '어렵', '닼', 'ㅋㅋㅋㅋㅋ', '이렇게', '어려울지', '몰랐어', '욬', 'ㅋㅋㅋㅋㅋ']\n",
      "['와', '진짜', '짱', '어렵다', 'ㅋㅋㅋ', '이렇게', '어려울지', '몰랐어요', 'ㅋㅋㅋ']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "\n",
    "text = \"와 진짜 짱어렵닼ㅋㅋㅋㅋㅋ 이렇게 어려울지 몰랐어욬ㅋㅋㅋㅋㅋ\"\n",
    "\n",
    "print(okt.morphs(text))\n",
    "print(okt.morphs(text, norm = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오다', '진짜', '짱', '어렵다', 'ㅋㅋㅋ', '이렇게', '어리다', '모르다', 'ㅋㅋㅋ']\n"
     ]
    }
   ],
   "source": [
    "print(okt.morphs(text, stem=True, norm = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soynlp\n",
    "- 기존에 없었던 새로운 단어를 추출하는 딥러닝 기반 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아이오', '아이', '가', '새로운', '앨범', '을', '발매', '하였다', '.']\n"
     ]
    }
   ],
   "source": [
    "print(okt.morphs(\"아이오아이가 새로운 앨범을 발매하였다.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soynlp==0.0.493\n",
      "  Downloading soynlp-0.0.493-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy>=1.12.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soynlp==0.0.493) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soynlp==0.0.493) (5.9.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soynlp==0.0.493) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soynlp==0.0.493) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->soynlp==0.0.493) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->soynlp==0.0.493) (3.5.0)\n",
      "Downloading soynlp-0.0.493-py3-none-any.whl (416 kB)\n",
      "Installing collected packages: soynlp\n",
      "Successfully installed soynlp-0.0.493\n"
     ]
    }
   ],
   "source": [
    "!pip install soynlp==0.0.493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아이오아이 나무위키 크롤링\n",
    "text = \"\"\"\n",
    " 최근 변경\n",
    " 최근 토론\n",
    " 특수 기능\n",
    "Search\n",
    "\n",
    "아이오아이\n",
    "최근 수정 시각: 2022-09-16 17:31:43\n",
    "\n",
    "분류 아이오아이\n",
    "Semi protect  로그인 후 편집 가능한 문서입니다.\n",
    "다른 뜻 아이콘  전세계 중고등학생을 대상으로 개최되는 컴퓨터과학 경시대회에 대한 내용은 국제정보올림피아드 문서를, 영화 '레디 플레이어 원'에 나오는 기업에 대한 내용은 레디 플레이어 원 문서를 참고하십시오.\n",
    "프로듀스 101 시리즈 로고\n",
    "프로젝트 그룹\n",
    "SEASON 1\n",
    "SEASON 2\n",
    "48\n",
    "X 101\n",
    "아이오아이\n",
    "Wanna One\n",
    "IZ*ONE\n",
    "X1\n",
    "아이오아이 로고\n",
    "\n",
    "임나영  김청하  김세정  정채연  주결경\n",
    "김소혜  유연정  최유정  강미나  김도연  전소미\n",
    "\n",
    "external/image.b...\n",
    "external/image.b...\n",
    "external/mimgnew...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2nd Mini Album\n",
    "miss me?\n",
    "베리베리베리 프사\n",
    "왼쪽부터 차례대로\n",
    "정채연ㆍ임나영ㆍ강미나ㆍ김소혜ㆍ주결경ㆍ김청하ㆍ전소미ㆍ김세정ㆍ김도연ㆍ유연정ㆍ최유정\n",
    "아이오아이 로고\n",
    "아이오아이\n",
    "I.O.I\n",
    "결성일\n",
    "2016년 4월 2일[1]\n",
    "데뷔일\n",
    "2016년 5월 4일\n",
    "(데뷔일로부터 +2332일, 6주년)\n",
    "활동 종료일\n",
    "2017년 1월 31일[2]\n",
    "데뷔 음반\n",
    "미니 1집 Chrysalis\n",
    "리더\n",
    "임나영\n",
    "유닛\n",
    "아이오아이 유닛 로고[3][4]\n",
    "소속사\n",
    "YMC엔터테인먼트 로고[5]\n",
    "스윙엔터테인먼트 로고[6][7]\n",
    "유통사\n",
    "CJ ENM 로고[8][9]\n",
    "스톤뮤직엔터테인먼트 로고 가로...\n",
    "장르\n",
    "K-POP, 팝, 댄스, 발라드, 신스팝\n",
    "팬덤\n",
    "앙둥이[10]\n",
    "SNS\n",
    "페이스북 아이콘 인스타그램 아이콘 트위터 아이콘\n",
    "\n",
    "1. 개요\n",
    "2. 로고\n",
    "3. 멤버\n",
    "3.1. 멤버 간 케미\n",
    "3.2. 프로듀스 101에서 멤버들\n",
    "3.3. 프로듀스 101의 멤버 별 평가 내역\n",
    "4. 활동\n",
    "4.1. 콘서트\n",
    "4.2. 5주년 라이브 방송\n",
    "5. 유닛\n",
    "6. 팬덤\n",
    "6.1. 응원법\n",
    "7. 음반\n",
    "8. 뮤직비디오\n",
    "9. 광고 및 화보\n",
    "10. 수상 내역\n",
    "10.1. 시상식\n",
    "10.2. 음악방송 1위 수상\n",
    "11. 여담\n",
    "11.1. 재결합 가능성?\n",
    "12. 논란 및 사건 사고\n",
    "13. 역대 프로필 사진\n",
    "14. 둘러보기\n",
    "\n",
    "1. 개요[편집]\n",
    "\n",
    "Yes, I love it! 아이오아이 입니다! 안녕하세요![11]\n",
    "I.O.I(아이오아이)는 2016년 5월 4일에 데뷔한 대한민국의 스윙 엔터테인먼트[12] 소속 11인조 걸그룹이다. 엠넷의 서바이벌 프로그램 프로듀스 101을 통해 결성되었으며 2017년 1월 31일까지 프로젝트 걸그룹으로 활동하였다.[13]\n",
    "\n",
    "그룹명 I.O.I는 Ideal Of Idol의 약자이며 가장 이상적인 아이돌이라는 뜻이 있다.[14] 또한 다른 뜻으로는 I Our I로 I와 I가 만나 Our가 되었다고 생각하는 멤버들도 있다.[15] 또한 프로듀스 101의 101명의 연습생을 의미하는 숫자 101[16]도 포함하고 있다.[17] # 팬들에게는 줄임말인 아오아와 앙순이, 앙앙이들이라는 애칭으로 불린다.\n",
    "2. 로고[편집]\n",
    "Idear Of Idol = I.O.I\n",
    "아이오아이 그룹명 의미\n",
    "Logo Teaser\n",
    "아이오아이 역대 로고\n",
    "아이오아이 로고\n",
    "아이오아이 로고 2\n",
    "아이오아이 Chrysalis ...\n",
    "기본 로고\n",
    "스탠바이 I.O.I\n",
    "Chrysalis\n",
    "아이오아이  로고\n",
    "아이오아이 손에 손잡고 로고\n",
    "아이오아이 miss me? 로...\n",
    "랜선친구 I.O.I\n",
    "손에 손잡고\n",
    "miss me?\n",
    "3. 멤버[편집]\n",
    "아이오아이 로고 화이트\n",
    "MM 임나영\n",
    "MM 김청하\n",
    "MM 김세정\n",
    "MM 정채연\n",
    "임나영\n",
    "김청하\n",
    "김세정\n",
    "정채연\n",
    "1995. 12. 18. (26세)\n",
    "대한민국 국기\n",
    "리더\n",
    "래퍼\n",
    "써브라임[A]\n",
    "1996. 02. 09. (26세)\n",
    "대한민국 국기\n",
    "메인댄서\n",
    "보컬\n",
    "MNH\n",
    "1996. 08. 28. (26세)\n",
    "대한민국 국기\n",
    "메인보컬\n",
    "\n",
    "젤리피쉬\n",
    "1997. 12. 01. (24세)\n",
    "대한민국 국기\n",
    "보컬\n",
    "\n",
    "BH[19]\n",
    "MM 주결경\n",
    "MM 김소혜\n",
    "MM 유연정\n",
    "MM 최유정\n",
    "주결경\n",
    "김소혜\n",
    "유연정\n",
    "최유정\n",
    "1998. 12. 16. (23세)\n",
    "중국 국기\n",
    "보컬\n",
    "\n",
    "周洁琼工作室[A]\n",
    "1999. 07. 19. (23세)\n",
    "대한민국 국기\n",
    "보컬\n",
    "\n",
    "S&P\n",
    "1999. 08. 03. (23세)\n",
    "대한민국 국기\n",
    "메인보컬\n",
    "\n",
    "스타쉽\n",
    "1999. 11. 12. (22세)\n",
    "대한민국 국기\n",
    "보컬\n",
    "래퍼\n",
    "판타지오\n",
    "MM 강미나\n",
    "MM 김도연\n",
    "MM 전소미\n",
    "\n",
    "아이오아이 로고\n",
    "강미나\n",
    "김도연\n",
    "전소미\n",
    "1999. 12. 04. (22세)\n",
    "대한민국 국기\n",
    "보컬\n",
    "래퍼\n",
    "젤리피쉬\n",
    "1999. 12. 04. (22세)\n",
    "대한민국 국기\n",
    "보컬\n",
    "\n",
    "판타지오\n",
    "2001. 03. 09. (21세)\n",
    "대한민국 국기\n",
    " |\n",
    "캐나다 국기\n",
    " |\n",
    "네덜란드 국기\n",
    "센터\n",
    "보컬\n",
    "더블랙레이블[21]\n",
    "\n",
    "3.1. 멤버 간 케미[편집]\n",
    "다른 뜻 아이콘  멤버간의 케미에 대한 내용은 아이오아이/멤버 간 케미 문서를 참고하십시오.\n",
    "3.2. 프로듀스 101에서 멤버들[편집]\n",
    "3.3. 프로듀스 101의 멤버 별 평가 내역[편집]\n",
    "4. 활동[편집]\n",
    "상세 내용 아이콘  자세한 내용은 아이오아이/활동 문서를 참고하십시오.\n",
    "4.1. 콘서트[편집]\n",
    "상세 내용 아이콘  자세한 내용은 타임슬립 - I.O.I 문서를 참고하십시오.\n",
    "4.2. 5주년 라이브 방송[편집]\n",
    "상세 내용 아이콘  자세한 내용은 I.5.I - Yes 문서를 참고하십시오.\n",
    "프로젝트 활동 종료 이후 사실상 첫 공식 스케줄이라고 볼 수 있다.\n",
    "5. 유닛[편집]\n",
    "상세 내용 아이콘  자세한 내용은 아이오아이/유닛 문서를 참고하십시오.\n",
    "6. 팬덤[편집]\n",
    "상세 내용 아이콘  자세한 내용은 아이오아이 팬덤 문서를 참고하십시오.\n",
    "6.1. 응원법[편집]\n",
    "상세 내용 아이콘  자세한 내용은 아이오아이/응원법 문서를 참고하십시오.\n",
    "7. 음반[편집]\n",
    "상세 내용 아이콘  자세한 내용은 아이오아이/음반 문서를 참고하십시오.\n",
    "8. 뮤직비디오[편집]\n",
    "아이오아이 로고\n",
    "M U S I C V I D E O\n",
    "2022년 7월 15일 09:27 기준\n",
    "순위\n",
    "게시일\n",
    "앨범/싱글\n",
    "곡명\n",
    "조회수[25]\n",
    "M/V\n",
    "1\n",
    "2018년 6월 26일\n",
    "miss me?\n",
    "너무너무너무 (Very Very Very)\n",
    "48,788,743\n",
    " 스톤뮤직엔터테인먼트 로고2\n",
    "2\n",
    "2018년 6월 26일\n",
    "Whatta Man\n",
    "Whatta Man (Good man)\n",
    "13,291,031\n",
    " 스톤뮤직엔터테인먼트 로고2\n",
    "3\n",
    "2016년 4월 11일\n",
    "Crush\n",
    "Crush\n",
    "13,076,830\n",
    " 스톤뮤직엔터테인먼트 로고2\n",
    "4\n",
    "2018년 6월 26일\n",
    "Chrysalis\n",
    "Dream Girls\n",
    "4,827,164\n",
    " 스톤뮤직엔터테인먼트 로고2\n",
    "5\n",
    "2018년 6월 26일\n",
    "소나기\n",
    "소나기 (DOWNPOUR)\n",
    "4,206,807\n",
    " 스톤뮤직엔터테인먼트 로고2\n",
    "원래는 전체 뮤비가 5,000~8,000만을 기록했으나 원본 뮤비들이 삭제되어 재업로드 되었다.[26]\n",
    "9. 광고 및 화보[편집]\n",
    "상세 내용 아이콘  자세한 내용은 아이오아이/광고 및 화보 문서를 참고하십시오.\n",
    "10. 수상 내역[편집]\n",
    "10.1. 시상식[편집]\n",
    "날짜\n",
    "시상식명\n",
    "수상 부문\n",
    "2016년\n",
    "5월 21일\n",
    "제11회 아시아모델페스티벌\n",
    "뉴스타상 가수부문\n",
    "11월 30일\n",
    "제24회 대한민국문화연예대상\n",
    "K-POP부문 가수상\n",
    "12월 2일\n",
    "2016 엠넷 아시안 뮤직 어워드\n",
    "여자 신인상\n",
    "2017년\n",
    "1월 14일\n",
    "제31회 골든디스크 시상식\n",
    "음반 신인상\n",
    "1월 19일\n",
    "제26회 서울가요대상\n",
    "신인상\n",
    "10.2. 음악방송 1위 수상[편집]\n",
    "날짜\n",
    "방송사\n",
    "프로그램명\n",
    "곡명\n",
    "비고\n",
    "2016년\n",
    "10월 26일\n",
    "MBC MUSIC 로고\n",
    "SHOW CHAMPION\n",
    "너무너무너무\n",
    "완전체 첫 1위\n",
    "10월 27일\n",
    "엠넷 로고\n",
    "엠 카운트다운\n",
    "10월 30일\n",
    "SBS 로고\n",
    "SBS 인기가요\n",
    "완전체 첫 지상파 1위\n",
    "2017년\n",
    "1월 29일\n",
    "SBS 로고\n",
    "SBS 인기가요\n",
    "소나기\n",
    "\n",
    "완전체 4관왕, 유닛 5관왕 총합 9관왕을 달성했다. 유닛의 수상 내역은 해당 문서를 참조.\n",
    "11. 여담[편집]\n",
    "한국인 9명, 중국인 1명, 한국·캐나다·네덜란드의 복수국적자 1명으로 이루어진 다국적 아이돌 그룹이다.\n",
    "임나영, 김청하, 정채연, 김소혜는 개신교이다.\n",
    "4월 2일 I.O.I 공식 V라이브 채널이 개설되었으나 2017년 2월 1일에 삭제되었다.\n",
    "1995년생~2001년생으로 구성되어 있으며, 활동 당시였던 2016년 기준 평균 나이는 18세였다. 활동 종료 후인 2022년 현재는 24세.\n",
    "아이오아이의 행사비에 대한 기사가 나왔다.# 프로듀스 101의 인기로 인해 신인 걸그룹인데도 불구하고 페이가 엄청나다.\n",
    "데뷔 쇼케이스 겸 팬미팅 티켓이 1,000원인데, 암표 가격으로 400배인 400,000원이 등장하기도 했다.# 심지어 그게 또 팔렸다. 이후 소문에 의하면 거래가 성사됐는지는 알 수 없지만 800,000원의 암표도 등장했다고 한다. 앞서 티켓비는 전액 기부한다고 밝혔는데, 이럴 거면 5,000원이나 10,000원 또는 그 이상으로 올려도 어차피 매진됐을게 뻔해서 기부액을 올렸어도 됐을 상황이다. 6월에 티켓 판매 수익금 3백만 원에 직원들이 7백만 원을 더한 1천만 원을 유니세프에 기부했다.#\n",
    "고려대 학생들을 대상으로 한 '축제 때 왔으면 하는 걸그룹' 설문 조사에서 2위를 기록했다.#, #그리고 연세대 축제에 갔다.\n",
    "대학생 441명을 대상으로 한 '축제에서 가장 보고 싶은 걸그룹' 설문 조사에서 4위를 기록했다.\n",
    "가수 브랜드평판지수 6월 조사에서 3위를 기록했다. 걸그룹을 기준으로 한 7월 순위는 4위다.\n",
    "빌보드가 '올해 상반기 데뷔한 유망한 K팝 가수' 중 한 팀으로 소개했다.\n",
    "Dream Girls가 대북방송용 노래로 쓰인다고 한다.#, #\n",
    "10월 26일 화보 인터뷰에서 원래는 유닛이 퍼포먼스팀, 보컬팀 2팀으로 나오려고 했는데 잘 안되어(일부 멤버들이 차출되어) 퍼포먼스팀(whatta man)만 나왔다고 한다.\n",
    "11월 13일 방영된 개그콘서트의 가족같은 코너에서 개그맨 김대성이 I.O.I의 해체를 반대한다는 피켓을 들며 시위하는 모습을 개그로 승화시켰다.(해당 기사) 참고로 김대성은 신보라와 I.O.I 데뷔 쇼케이스 진행을 맡았었다.\n",
    "2017년 1월 한 기사에 따르면 10개월간 벌어들인 돈이 무려 100억이라고 한다. 프로젝트로 잠시 활동을 하고 해체를 하는데도 불구하고 저 정도의 어마어마한 액수를 벌어들인 것이다. 수익 배분은 경비를 제외하고 이들을 첫 제작한 CJ E&M이 25%, 매니지먼트를 맡은 아이오아이의 소속사인 YMC엔터테인먼트에서 25%, 각각의 멤버들과 소속사가 50%를 갖는 형태. 다만 각각의 기획사 마다 연습생 및 소속 연예인과의 정산 비율이 달라서 계산하기 어렵고 또한 100억 이라는 수치가 순수익이 아닌 '단순 매출액'이기 때문에 앞서서 언급된 것처럼 경비를 제외한다면 연습생들에게 돌아갈 몫은 의외로 적다고 봐야 한다.[27]\n",
    "2017년 1월 25일 엘리트 교복 광고 촬영을 끝으로 아이오아이 완전체 공식활동이 종료되었다.\n",
    "2017 MAMA에 일본 걸그룹 AKB48과 콜라보레이션 무대를 갖는 것이 확정되었다.관련 기사 단, 11명 완전체가 아닌 일부 멤버들만 참여했다. 이 멤버들은 2017년 기준 MAMA 신인 여자가수상 후보 자격을 갖춘 임나영, 김청하, 주결경, 최유정, 김도연이다. 이 콜라보레이션 무대에는 이들이 소속된 프리스틴, 위키미키, AKB48에 데뷔를 앞두고 있던 프로미스나인과 아이돌학교 class 1(데뷔 최종 문턱에서 탈락한 멤버들을 주축으로 하는 연습생 팀)이 합류했다. 그리고 여자신인상 시상에 임나영, 김청하, 주결경, 최유정, 김도연이 전년도 수상자인 I.O.I 멤버 자격으로 수상자로 참석했다. 여자 신인상 후보가 위 5명의 멤버가 멤버가 속한 프리스틴, 위키미키, 김청하 중 한 팀이 수상이 유력해서 I.O.I 멤버끼리의 선의의 경쟁이 되었으며, 결국 프리스틴이 여자 신인상을 수상했다.\n",
    "복면가왕에 아이돌 그룹 최초로 7명이 도전자로 출연했으며,[28] 판정단으로는 김청하, 김세정, 정채연, 최유정, 강미나가 출연했다.[29] 네이버TV 복면가왕 스페셜에서도 I.O.I가 출연한 방송분의 풀영상이 올라와 있다.\n",
    "2018년 설특집 아육대의 촬영을 위해 1월 중순경 아이오아이 멤버 8명이 다시 뭉쳤는데,(임나영, 김세정, 정채연, 주결경, 유연정, 최유정, 강미나, 김도연) 이 멤버들이 각 소속팀인 프리스틴, 구구단, 다이아, 우주소녀, 위키미키의 출전 선수 자격으로 촬영차 뭉치게 되었고 아이오아이 팬들은 아육대에 고마움을 표현했었다. 하지만 안타깝게도 김청하, 김소혜, 전소미는 개인적인 스케줄 및 각자의 사정으로 인해 아육대 촬영에 함께 참여하지 못한 것으로 알려져 한편으로는 아쉬움도 존재했다. 하지만 현장 영상을 보면 멤버들끼리 많이 반가웠는지 서로 모여서 얘기를 하거나 수고했다며 껴안는 등 훈훈한 모습을 보여 팬들을 웃게 했다.\n",
    "2018 서울가요대상의 참석자로 임나영, 김청하, 주결경이 뭉쳤었다. 이들은 그룹 프리스틴, 솔로가수로 무대에 오르기 위해 모였었다. 이들의 큰 바램이 있다면 곧 방영이 될 예정인 프로그램 프로듀스 48에서 아이오아이 완전체인 11명이 모두 다시 한 번 뭉쳤으면 하는 소원과, 이번 2018년도에 스케줄을 진행하면서 아이오아이 멤버들이 자주 모였으면 하는 바램도 내비췄다.기사 그리고 완전체 출연을 추진중인 것으로 알려졌다.기사 팬들은 완전체를 볼 수 있다는 것에는 긍정적인 반응을 보였지만, 엠넷이 프로듀스 48의 홍보용으로 아이오아이를 이용하려 한다는 의심과 함께 부정적인 반응을 보이는 팬들이 많다.\n",
    "2018년 설연휴 전날에 오랜만에 앨범이 나왔다.기사 비록 다 함께 모여 작업하지는 않았지만, 2016년 리우 올림픽 당시에 해당 올림픽을 응원하기 위한 응원가인 '손에 손 잡고'라는 곡을 전주 부분에 있는 국민들의 응원메시지를 삭제하고 오직 아이오아이 멤버들의 목소리로만 구성이 되게끔 편곡한 곡이다. 아마 평창올림픽을 기념해서 나온것으로 보인다. 팬들은 오랜만에 '아이오아이'라는 이름으로 공개된 곡에 반가움과 아이오아이에 대한 그리움을 표했다.\n",
    "고등학교 음악 교과서에 올림픽 응원곡으로 '손에 손 잡고'가 기술되어 있다.#\n",
    "2017년과 2018년에 데뷔 기념 광고가 홍대입구와 청담역에 걸렸다. 2017년에는 버스에도 했었지만(#) 18년에는 지하철 광고만 걸렸다.#\n",
    "아이오아이 멤버들이 루게릭 환우들을 위한 아이스 버킷 첼린지에 함께 참여했다는 것이 확인되었다. 참여한 멤버들은 김소혜, 강미나, 최유정, 유연정, 김청하, 정채연으로 확인되었다. 각자 개인 SNS 및 자신의 해당 그룹 공식 SNS를 통해 참여하는 모습을 공개했다. 이에 아이오아이의 팬들이 멤버들에게 칭찬을 아끼지 않는 모습들도 보여졌다.\n",
    "프로듀스 48 마지막회에도 첫회 예고편에 이어서 아이오아이 멤버들이 Wanna One과 함께 출연했었다. 단, 완전체는 아니고 임나영, 김세정, 최유정, 유연정, 강미나, 김도연, 전소미만 참석했으며, 나머지 멤버들은 개인스케줄 때문에 불참했다. 그러나 아이오아이 멤버들 모두 현재 각자의 영역에서 바쁜 일정을 소화하는 중이고, 워너원도 일정이 빠듯하기에 두 그룹의 멤버들의 현 상황들을 다 고려하지 않는 선택이라고 프로그램을 상대로 불만이 터져나오기도 했다.#\n",
    "2019년 3월 9일에 오랜만에 I.O.I의 99년생 멤버들 전원이 다 뭉쳤다. I.O.I 멤버들 중 거의 절반이 사적인 자리에서 뭉친 것이 되기 때문에 팬들은 이들에게 반가움을 표했다. 사진속에서는 김소혜, 유연정, 최유정, 김도연, 강미나가 함께 미소를 띄는 모습이 보여서 팬들도 덩달아 미소짓게 했다.#1#2\n",
    "아이오아이가 새로운 소속사인 STUDIO BLU에 소속 아티스트로 합류하면서 같은 회사 아티스트인 헤이즈와 한솥밥을 먹게 되었다. 주로 음반과 관련된 업무를 맡고 매니지먼트는 스윙 엔터테인먼트에서 맡는다.\n",
    "활동 종료 후, 2020년 3월 기준 음악방송 1위 타이틀을 차지한 멤버는 다음과 같다.\n",
    "정채연: 다이아 통산 1회 달성\n",
    "유연정: 우주소녀 통산 9회 달성\n",
    "김세정: 솔로 활동 2회 달성\n",
    "김청하: 2017년 6월 솔로 데뷔 이후 2019년 7월 기준 13회 달성\n",
    "전소미: 솔로 활동 2회 달성\n",
    "프로듀스 X 101의 데뷔 그룹인 X1이 결성되면서 프로듀스를 통해 탄생된 3개의 팀인 I.O.I, IZ*ONE, X1이 동일한 시기에 함께 활동하게 될 예정이었다. 그러나 안준영 PD가 프로듀스 시리즈에 대한 순위를 조작했다는 사실을 시인함으로써 X1이 해체하였고 I.O.I의 재결합 역시 불투명해지게 되었다. 자세한 내용은 아래 문단 참고.\n",
    "2019년 12월에 최유정이 개인 인스타를 개설하면서 모든 멤버들이 SNS 활동을 하게 되었다.\n",
    "2020년 8월 4일, 공식 페이스북 계정에 소개글이 업데이트되었다.(#)\n",
    "최근 전소미, 김세정, 김청하가 아이오아이를 위한 곡을 썼다고 직접 밝혔다. 청하에 의하면 소미가 쓴 곡을 듣고 좋았다고 했을 정도로 퀄리티 좋은 곡을 뽑아낸 것으로 추정. 만일 컴백이 확정된다면 해당 곡을 들고 나올 수 있을지 기대하는 팬들도 늘었다. 청하, 소미, 세정[30][31]\n",
    "11.1. 재결합 가능성?[편집]\n",
    "I.O.I는 소속사가 서로 다른 멤버들로 구성되어 계약상 1년 정도의 단기간으로 활동하는 '프로젝트 걸그룹'이다. 그룹이 해체되어 멤버들이 각자의 소속사로 돌아가는 것이 불가피하고, 결국 2017년 1월 31일을 끝으로 해체되었다. 그리고 멤버들은 5년 후에 다시 뭉치자는 팬들과의 약속을 끝으로 각자의 소속사로 흩어진 상황이다.\n",
    "\n",
    "그러던 중 2019년을 들어서 루머 기사가 자주 뜨기 시작했다. 2월 26일 갑자기 I.O.I의 재결합이 논의중이라는 기사가 올라오면서 각종 포털사이트의 실검에 오르내렸으나 반박 기사가 올라오면서 # 사실무근으로 끝이 났다. #\n",
    "\n",
    "이 후, 4월 30일과 6월 13일에도 비슷한 패턴의 기사가 또 올라왔으나 마찬가지로 모두 사실무근으로 끝났다. 다만 재결합에 대한 긍정적인 논의 및 활동을 위한 멤버들과의 조율은 진행중이라고 관계자들이 직접 전했다.#4#5관련영상 계속되는 희망고문에 네티즌들과 팬들은 재결합과 관련된 기사에 대한 신뢰를 잃었는데, 이는 I.O.I 재결합과 관련된 루머가 이곳에서 논란이 발생할 때마다 올라왔기 때문에, I.O.I를 본인들의 논란을 덮는 언플 용도로 사용하는 것이 아니냐는 이도 나오고 있는 상황이다.\n",
    "\n",
    "한편, 활동을 멈춘 채 장기간 방치되던 프리스틴이 끝내 해체되면서 임나영이 플레디스에서 나가고 주결경은 플레디스에 남아 중국 활동을 이어가게 되면서 재결합에 차질이 생길 것으로 보인다.\n",
    "\n",
    "그런데 6월 28일, 재결합이 확정되었다는 기사가 추가로 올라왔고, 뒤이어 재결합이 확정되었다는 기사가 우후죽순으로 나오기 시작했다. 후에 다음과 같은 입장이 올라오면서 4번의 재결합 루머만에 드디어 재결합이 확정되었고 # 현재 10월 컴백을 목표로 하고 있으며, 현재 세부사항을 조율중이라고 했고# 7월 1일 0시, 스튜디오 블루 인스타그램을 통해서 전소미와 유연정을 제외한 9명이 2019년 10월 재결합을 한다는 소식이 전해졌다.# # 그러나 당초 기사에서 보도되어 나온 것처럼 6개월의 활동이거나 활동을 추가적으로 할 수 있는 기회도 열려있다면 완전체로서의 활동도 가능성이 아주 없지는 않다.\n",
    "\n",
    "그동안의 소식들을 종합해보면 CJ ENM에서 또 불렀을 가능성이 높아보인다. 일부 멤버들(최유정#, 전소미#, 김청하#)이 쇼케이스 무대에서 재결합 질문에 전부 모른다는 식으로 얘기한 것도 있고 그동안 전에도 몇차례 불렸던 사례가 있었기 때문인데 어찌됐든 이것이 사실이면 I.O.I로서 활동을 하기 위해 부른 것은 이번이 처음이라고 볼 수 있다.\n",
    "\n",
    "7월 1일, 공식적인 보도 자료가 나왔다. 유연정과 전소미를 제외한 9인조로 컴백을 확정지었으며, 새 앨범은 스튜디오 블루에서 제작을 맡고, 매니지먼트는 스윙엔터테인먼트와 협력하여 진행할 예정이다.#이로써 재결합을 총괄적으로 주도한 게 CJ E&M임이 밝혀지게된 셈이다. 공식 보도자료를 통해서 7월 1일에 새 앨범의 재킷 촬영을 진행한다고 밝혔다.# 공식적으로 컴백이 확실하다는 증거의 기사들이 나왔지만, 이것이 단발성으로 하는 재결합인지 아니면 지속적으로 1년에 한두 번정도는 활동하는 재결합인지는 아직 밝혀진바 없다.\n",
    "\n",
    "그러던 중 2019년 9월 6일, 갑작스럽게 앨범의 완성도를 높이기 위해 12월로 컴백을 연기한다는 기사가 나왔다. 11인 완전체 활동의 가능성도 열어둔 것으로 보아 완전체 컴백도 기대해 볼 수 있는 상황이 되었다.# 그러나 앨범의 완성도는 명분일 뿐이고 실제로는 엠넷 서바이벌 프로그램 투표 조작 사건과 관련해 수사가 모든 시리즈로 확대된 데에 따른 몸 사리기 차원이 아닌가라는 추측도 있다.\n",
    "\n",
    "그러나 2019년 10월 29일 스포츠서울 단독 기사를 통해 재결합의 무산 가능성을 알렸다. 최유정의 건강 문제, 주결경의 중국 스케줄과 전소미, 유연정이 이미 한 차례 불참 입장을 전해왔던 가운데 7인조 컴백은 의미가 없음을 판단한다고 언론사를 통해 전했다고 한다.\n",
    "\n",
    "예정된 컴백까지 한 달 남은 시점에 밝힌 것이기 때문에 공식 입장을 전하기 전까지 기다려야 하고, 지금 당장에 재결합을 논하기에는 시기상조이기도 하다. 또, 아직 현재 소속사인 스윙 엔터테인먼트와 STUDIO BLU의 공식 입장이 없기에 확실하게 무산이 결정이 된 상황은 아니라고 볼 수 있다. 그러나 이로 인해 재결합 가능성이 더 내려간 것은 부인하기 힘들다.\n",
    "\n",
    "엠넷 '프로듀스X101' 등의 투표조작 의혹을 수사 중인 경찰이 프로듀스 시리즈의 시즌 1·2에서도 조작 정황을 포착한 것으로 알려졌다. 서울경찰청 사이버안전과는 그룹 'I.O.I'와 'Wanna One'을 배출한 프로듀스 시즌 1·2의 최종회 투표 결과와 시청자 투표 데이터 간 차이를 발견해 수사를 벌이고 있다.# 구속 수감된 안준영PD가 처음에는 시즌1·2의 조작을 부인 했었지만, 경찰이 증거를 확보하고 추궁이 이어지자 결국엔 프듀 1·2의 조작을 일부 시인했다.# IZ*ONE이나 X1이 안준영PD와 김용범CP의 구속이 있고 나서 모든 활동이 올스톱된 상황인데, I.O.I의 재결합은 사실상 힘들어졌다고 봐야겠다.\n",
    "\n",
    "I.O.I는 애초 12월 재결합할 예정이었지만, 안PD의 조작 시인으로 대부분의 소속사가 I.O.I 활동에 참여하지 않는 쪽으로 마음을 굳혔다. 검찰의 공소장에는 1차 순위 발표 때 순위 바꿔치기가 있었던 것으로 드러났지만 이것만으로 최종 멤버 선발이 깨끗하다고 단정짓기는 무리다. 이로써 재결합은 사실상 무산되었으며,# 앞으로도 가능성은 거의 없을것으로 보인다. 이 논란으로 인해 이미지 회복이 쉽지 않을 것으로 예상되기 때문이다.\n",
    "\n",
    "2019년 12월 13일 I.O.I 역시 파이널에서 멤버 1명이 바꿔치기 되었다고 언론에서 발표하였다.이는 안준영PD가 프로듀스101 시즌1의 최종 집계 결과에는 관여하지 않았다고 판단하여 검찰이 제출한 프로듀스101 시즌 1의 최종 결과 조작 혐의에 대한 불기소 이유서에 따른 것이다. 2020년 11월 18일 안준영, 김용범 등의 항소심에서 재판부가 발표한 프로듀스101의 피해 인물에는 1차 투표의 피해자만 있고 파이널은 없었다. 따라서 데뷔조가 바뀐 것은 의도적인 조작은 아니었다고 최종적으로 판단한 것이다. [32][33]\n",
    "\n",
    "2020년 2월 17일에 IZ*ONE이 활동을 재개하기로 함에 따라 아이오아이의 재결합에 일말의 가능성이 열렸지만 위에서 언급했듯이 몇몇 멤버들의 합류 여부가 여전히 미지수인 상황에서 활동 재개가 이루어질 지는 불투명하다.[34] 멤버 개개인들의 아이오아이에 대한 애정도도 높고 이윤을 추구하는 소속사 입장에서도 큰 파이를 가져다줄 아이오아이는 여전히 탐나는 브랜드이기 때문에 적절한 시기에 눈치를 봐가며 재결합을 진행할 가능성도 존재했지만.......\n",
    "\n",
    "2020년 3월 25일, 주결경이 소속사인 플레디스와 2019년 9월부터 법적 분쟁 중이라는 사실이 뒤늦게 알려지면서 재결합이 힘들지도 모른다는 극소수의 의견도 있으나 오히려 플레디스로부터 해방되어 운신의 폭이 넓어져 아이오아이에 합류할 가능성이 커졌다는 의견도 있다. 하지만 주결경은 딱히 한국 활동의 의향이 없는 듯 하며, 현재 중국활동에만 주력하고 있다. 본인이 화상통화에서 재결합에 꼭 참가하고 싶다고 했기 때문에 본인이 진정으로 원한다면 딱히 어려움은 없을 듯 하겠지만 주결경은 물론 다른 팀의 중국인 멤버들이 SNS에서 보이는 친중국 발언으로 중국인 멤버들에 대한 반감이 커지고 있기에 영향이 아예 없다고 하기는 어렵다. 3년간 한국활동이 없었기 때문에 한국 공연 비자도 만료되어 비자 재발급을 받아야 한다.\n",
    "\n",
    "드디어 2021년 5월 4일에 아이오아이의 데뷔 5주년을 기념해 라이브 생방송을 예정하고 있다는 소식이 전해졌다. # 그러나 최초 보도와는 달리 완전체는 아니다. 다른 스케줄이 잡힌 미나, 중국에 체재중[35]인 결경은 불참한다.# # 이 날 진행된 라이브는 각자 멤버들의 근황, 2016년 아이오아이 활동 당시 사진 및 영상에 대한 추억 이야기 등의 주제로 토크쇼 위주로 진행되었다. 따로 노래나 무대를 서진 않았으나 팬들은 5년 만에 재개된 첫 라이브 방송이라는 의의를 두었고 실제로 여러 커뮤니티에서도 이렇게 뭉쳐서 서로 이야기하고 재밌게 웃는 모습만 봐도 가슴이 뭉클해진다는 반응을 보였다.\n",
    "\n",
    "그리고 이 날 불참한 주결경도 영상통화로나마 인사를 하게 되어 팬들의 감동을 한번 더 터뜨렸다.[36] 라이브 방송 중 멤버들이 2017년 해체 당시에 정해지지 않았던 아이오아이의 공식 팬덤명을 멤버들끼리 정해보고 싶다고 언급하였고, 추후에 공지할 수 있는 기회가 된다면 공지하겠다고 말하였다. 라이브 방송 종료 이후 멤버들의 인스타그램 게시물 및 스토리에 여러 사진과 영상이 올라와 팬들의 가슴을 다시 한번 뭉클하게 하였다.\n",
    "\n",
    "뒤이어 같은 프로그램 출신 워너원의 재결합 소식과 함께 반가운 소식이 하나 더 들려왔다. 바로 CJ ENM측에서 디스패치와의 인터뷰를 통해, 워너원 뿐만 아니라 아이오아이 및 다른 팀들의 활동 역시 이들이 원한다면 서포트를 할 준비가 되어 있다는 것을 직접 밝혔다.# 그리고 현 시점에서 상단 여담을 통해 알 수 있듯이 일부 멤버들이 아이오아이의 추후 후속곡에 대해 직접 작사•작곡에 참여했거나, 2021년 5월경 라이브를 진행했다는 점, 멤버들의 꾸준한 교류가 있어왔던 점을 보아서 충분한 가능성 및 기대감도 또 다시 열리고 있는 상황이다.\n",
    "\n",
    "결정적으로 한 팬이 네이트 판에 올린 정리글이 있는데, 해당 글에 따르면 멤버들 스케줄이 공교롭게도 2022년 연초에 전부 끝난다는 것. 일각에서는 CJ에서 서포트를 언급한 시기와 멤버들의 개별 활동 마무리 시기가 거의 일치해서 2022년에 정말 컴백하는 것이 아닌가? 라는 여러 추측들이 생기고 있다.\n",
    "\n",
    "게다가 청하, 연정, 소미와 같은 멤버들이 컴백, 예능, 콘서트, 월드투어 등 다양한 활동에 대한 언급을 5주년 라이브 때 했었기에 가능성이 더 커졌다. 예전에 유정의 인스타에 올라온 해당 영상이 멤버들이 컴백 논의를 위해 만난 이후의 영상이 아닌가 라는 추측도 생겼다. 뒷배경이 회의실의 느낌과 매우 흡사하기 때문. 청하의 말에 따르면, 지난 2021년, 올 해 포함 앞으로의 크리스마스는 아이오아이 멤버들과 함께할 예정이라 밝혔었던 만큼 교류 역시도 자주 이뤄지고 있다는 것이 확인됐다. 그리고 재결합 스케줄 이후의 영상 중 하나에서 한 멤버가 \"또 만날거다!\" 라고 말을 했던 영상도 최근 팬들에 의해 발견되었다.# 직속 후배 그룹인 워너원에 이은 다음 컴백주자가 될 것이라는 추측이 긍정적인 측면으로 변화되는 영상이라는 반응들도 생기고 있다.\n",
    "\n",
    "또 다른 해외 팬들의 추측에 따르면 이번 2021 MAMA에서 진행했던 워너원의 무대 초기 배경인 아래 이미지들이 다음 주자로 아이오아이의 컴백을 예고하는 것이 아니냐 라는 말도 나왔었다. 아니면 I.O.I를 의미하는 글자가 101(원오원)이라는 의미할 수도 있다. 즉, 엑스원의 X를 보면 프듀 그룹들이 마마에 나올 수도 있다는 증거. 과거에도 엠넷은 MAMA를 통해 티저나 예고를 공개하는 케이스가 많았기 때문.\n",
    "아이오아이 컴백 추측 이미지\n",
    "아이오아이 컴백 추측 이미지 ...\n",
    "\n",
    "결정적인 증거로, 과거 지상파 체널 중 유일하게 활동했던 KBS에서 같은 프로그램 출신인 워너원, 아이즈원은 컴백 희망 과거 무대 영상을 편집해 유튜브에 업로드한 반면, 아이오아이는 올리지 않았다. 같은 방송 업계의 기업이기에 2022년에 컴백을 앞두고 있는 걸 사전에 미리 인지한 직후라서 올리지 않은 것이라는 추측도 생겼다. 리스트\n",
    "아이오아이 재결합 증거 3\n",
    "\n",
    "추가로 확보한 추측에 따르면, 아이오아이의 공식 페이스북 프로필 사진이 2021년 3월 19일에 한차례 변경이 되었다는 것. 컴백을 하지 않는 아티스트의 프로필 사진이 변경되는 사례가 지금까지 매우 드물었기[37] 때문에 컴백을 앞두고 프로필 사진을 변경했다는 추측도 팬들 사이에서 돌고 있는 중이다.\n",
    "아이오아이 컴백 증거 2\n",
    "\n",
    "최근 또 다른 정황이 팬들에 의해 발견이 됐는데, 2022년, 아무런 활동이 없던 아이오아이의 트위터 프로필 로고가 기존의 로고 크기에서 비정상적으로 길어진 것으로 변경이 되었다(!). 이 점을 보아, 아이오아이 측에서 현재 컴백을 위해 적절한 시기를 주시하고 있는 상황이 아닌가 라는 추측도 생겨났다.\n",
    "아이오아이 트위터 프로필 로고...\n",
    "\n",
    "또 한 최근 오디션 프로그램 관련 기사에서 실린 아이오아이의 자료 사진이 스윙엔터테인먼트에서 제공이 된 것으로 보아, 이미 팀 및 멤버 전원[38]이 스윙으로 이적 및 계약하여 소속이 되었다는 것 역시 확인이 되었다. 아이오아이가 현재 멤버들간의 교류 역시 이전보다 더 많아지고 활발해진 것 역시도 팬들에 의해 자주 목격되고 있기 때문에 희망을 가져도 될 것 같다는 일부 팬들의 의견도 생기고 있다.\n",
    "\n",
    "2022년 7월, 갑자기 아이오아이의 기존 네이버 프로필이 타 프로듀스 출신 그룹들처럼 신형 네이버 프로필 툴로 바뀌었다(!). 네이버 프로필은 해당 인물 관계자 및 본인이 수정 요청을 해야 변경이 가능한데, 최근에 변경 요청을 아이오아이 관계자가 진행한 듯 보인다.[39]\n",
    "\n",
    "다만 위에서 언급했듯 주결경이 중국에서 보이는 친중적 정치성 행보 때문에 일부 팬들은 주결경의 복귀를 반대하고 있다. 또한 김소혜 역시 학교폭력 사실이 밝혀져 복귀에 걸림돌이 될 가능성이 있다.\n",
    "12. 논란 및 사건 사고[편집]\n",
    "상세 내용 아이콘  자세한 내용은 아이오아이/논란 및 사건 사고 문서를 참고하십시오.\n",
    "13. 역대 프로필 사진[편집]\n",
    "Pre - Debut\n",
    "아이오아이 프로필 018\n",
    "아이오아이 프로필 017\n",
    "Chrysalis\n",
    "IOI 프사\n",
    "IOI 프사 02\n",
    "miss me?\n",
    "베리베리베리 프사\n",
    "아이오아이 miss me? 0...\n",
    "14. 둘러보기[편집]\n",
    "아이오아이 유닛 로고\n",
    "\n",
    "임나영  김청하  주결경  김소혜  최유정  김도연  전소미\n",
    "external/image.b...\n",
    "external/image.b...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "아이오아이 로고 의 리얼리티\n",
    "스탠바이 아이오아이\n",
    "랜선친구 아이오아이\n",
    "아이오아이 로고 의 노래\n",
    "Dream Girls\n",
    "벚꽃이 지면\n",
    "스윙엔터테인먼트 로고 그라데이...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "아이오아이\n",
    "아이오아이\n",
    "\n",
    "영업 홍보용 에어간판 제작\n",
    "www.airbible.com\n",
    "입체에어간판춤추는 간판맞춤 인형탈액션 신제품\n",
    "눈에 띄는 홍보용 에어간판, 춤추는 간판, 인형탈 제작, 공장직거래, KC인증\n",
    "\n",
    "한번에 합격!강화운전전문학원\n",
    "ganghwa.dubuplus.com\n",
    "김포, 강화도 운전면허전문학원, 전지역 셔틀버스운행, 한번의합격률, 빠른면허취득.\n",
    "GAM실용음악학원\n",
    "www.gamlove.org\n",
    "김포기타학원,체계적인 개별교육,어쿠스틱핑거스타일,일렉기타,성인 아동 누구나 가능\n",
    "[1] #\n",
    "[2] 2021년 5월 4일 5주년 기념 라이브 방송을 진행했지만 당초 알려진 것과는 달리 완전한 재결합은 아니었다.\n",
    "[3] 김세정, 정채연, 강미나, 유연정이 빠진 7인 유닛.\n",
    "[4] 이외에도 주결경, 강미나가 자체적으로 만든 비공식 유닛인 옐로우팝콘도 있다. 주결경이 멤버들 중 강미나만 유닛 멤버로 영입했다.\n",
    "[5] 아이오아이의 데뷔 이후 활동 기간인 2016. 4. 2. ~ 2017. 1. 31까지 매니지먼트와 기획을 담당하던 회사다.\n",
    "[6] CJ ENM이 직접 활동에 대한 서포트 계획을 밝혔다. 예정대로 스윙 측에서 매니지먼트를 진행할 예정. 구글의 아이오아이 그룹 프로필에서도 이미 스윙 엔터테인먼트 소속 아티스트로 수정이 완료되어있다. 아이오아이 소속사 표기 구글 ...\n",
    "[7] 최근 한 기사에서 아이오아이 관련 자료 사진을 제공한 회사가 스윙 엔터테인먼트인 것으로 밝혀졌다. 아이오아이 스윙 엔터테인먼트\n",
    "[8] 현재 유통사 및 레이블. 로엔에서 CJ로 변경.\n",
    "[9] 과거 로엔, 현재 카카오M이 I.O.I 활동시기였던 2016~2017년까지 아이오아이의 앨범 유통을 맡았으나, 이후 CJ ENM 산하 스톤뮤직엔터테인먼트로 넘어가면서 카카오 계열의 1THEK에 업로드 된 모든 뮤직비디오가 삭제 되고, 스톤뮤직 이름으로 새로 업로드 되었다.\n",
    "[10] 2021년 5월 4일에 정해진 임시 팬덤명. 추후 확정 후 재공지 예정이라고 멤버들이 직접 언급했다.\n",
    "[11] 대부분의 아이돌 그룹이 인사 멘트를 \"안녕하세요\"로 시작하는 것과 차별화를 주기 위해 그룹의 소개말 뒤에 붙이는 것으로 정했다.\n",
    "[12] 구글 프로필상 현 공식 매니지먼트 소속사. 데뷔 후에는 YMC엔터테인먼트였다가 현재는 스윙으로 이적.\n",
    "[13] 2021년 5월 4일 첫 스케줄을 진행하며 재결합에 성공했다. 이미 프로필상 소속사 수정도 마친 상태.\n",
    "[14] 스탠바이 I.O.I 1회 시작 화면에서 소개.\n",
    "[15] 5월 4일 V앱 방송 1st Mini Album ＜Chrysalis＞ V-Live에서 소개. 영상 6분 35초부터 참고.\n",
    "[16] 원래 '101'에는 '기초 과정, 입문, 개론, 초보, 기본'이라는 사전적 의미가 있다. 101의 10-1번 문단을 참조해볼 것. #, # 프로듀스 101 1회 시작 화면에서도 101에는 입문이라는 뜻이 있다고 소개된다.\n",
    "[17] 트와이스의 우아한 사생활에서 채영과 소미가 통화하는 중에 채영이 I.O.I의 뜻이 무엇이냐 물어봤을 때 소미는 숫자 101명을 가리키며 I.O.I가 거기서 유래했다고 했다.\n",
    "[A] 18.1 18.2 활동 당시 플레디스엔터테인먼트소속.\n",
    "[19] 2022년 9월 MBK엔터테인먼트와 계약종료\n",
    "[21] 활동 당시 JYP엔터테인먼트 소속.\n",
    "[22] 전소미 - Bang Bang, Yum-Yum / 김세정 - 양화대교, Fingertips / 김청하 - Push Push / 주결경 - 보름달 / 정채연 - 다시만난세계 / 김도연 - LA chA TA, 같은 곳에서 / 강미나 - 몰라요, 24시간 / 임나영 - Ah, Say My Name\n",
    "[23] 전소미,정채연(2조)/유연정(1조)\n",
    "[24] 주결경(1조)/강미나(2조)\n",
    "[25] Stone Music Entertainment의 영상 조회수 기준\n",
    "[26] 본래였으면 너무너무너무는 이미 1억뷰가 훨씬 넘었을 것이다.\n",
    "[27] 그들이 당장 큰 정산금을 받지는 못하지만 I.O.I 활동을 통해 돈으로 환산할 수 없는 인지도를 얻었기 때문에 엄청난 이익이라고 연예매체들은 주장 하지만 2016년도에 I.O.I만 인지도를 얻은 것이 아니라 걸그룹의 전체적인 세대교체가 이루어진 한해였기 때문에 과연 연예매체들이 주장하는대로 앞으로도 장미빛 미래가 그들에게 펼쳐질지는 두고봐야 할 문제이다.\n",
    "[28] 하얀시 눈이군 쌓이면 우리마을, 워커홀릭 개미소녀, 대하드라마 여주인공 꽃새우, 오늘의 럭키걸 네잎클로버, 노래에 꽃쳤어요 꽃순이, 다 불어버리겠다 민들레소녀, 가왕이 하나면 하나지 둘이겠느냐~ 영심이가 도전자로 참가했으며 <우리마을>, <개미소녀>는 I.O.I 활동중에 출연했고 나머지는 해체 이후 출연.\n",
    "[29] 재미있게도 최유정이 판정단으로 출연했을때 주결경이 '노래에 꽃쳤어요 꽃순이'로 출연했다.\n",
    "[30] 해당 기사는 아카이브를 통해 접속하여 링크 발췌.\n",
    "[31] 청하는 심지어 유명 프로듀서와 협업해 곡 작업을 했다고 한다(!).\n",
    "[32] 한 기자에 따르면 최종 데뷔조가 바뀐 것은 투표 집계를 관행상 실제 고지한 시간보다 빠르게 마감하여 발생했다고 한다.\n",
    "[33] 법원에서 이 사안을 언급하지 않았을 뿐, 당시 방송통신심의위원회는 이 사안도 징계사유로 포함하였다.\n",
    "[34] 그나마 최유정과 김도연은 2020년 2월 말 위키미키의 컴백에 맞춰 활동을 재개한다.\n",
    "[35] 코로나 사태때문에 한국에 일단 입국하면 14일 격리, 다시 돌아가면 중국에서는 21일 격리를 해야 하니, 사실상 참가가 불가능했다.\n",
    "[36] 주결경과 돈독한 사이였던 임나영은 화상통화도중 눈물을 보이기도 했다.\n",
    "[37] 한국을 포함해 미국, 영국 등 다양한 국가의 아티스트들 역시 새로운 활동을 앞뒀을 때 프로필 사진 변경 작업을 진행한다. 때문에, 아이오아이가 컴백할거란 추측이 더 커진 것.\n",
    "[38] 그룹 활동 한정 전원 이적.\n",
    "[39] 아이오아이의 새 활동에 대한 사전 작업일 수 있어 프로필 수정에 컴백에 대한 귀추도 주목이 되고 있다.\n",
    "크리에이티브 커먼즈 라이선스\n",
    "이 저작물은 CC BY-NC-SA 2.0 KR에 따라 이용할 수 있습니다. (단, 라이선스가 명시된 일부 문서 및 삽화 제외)\n",
    "기여하신 문서의 저작권은 각 기여자에게 있으며, 각 기여자는 기여하신 부분의 저작권을 갖습니다.\n",
    "\n",
    "나무위키는 백과사전이 아니며 검증되지 않았거나, 편향적이거나, 잘못된 서술이 있을 수 있습니다.\n",
    "나무위키는 위키위키입니다. 여러분이 직접 문서를 고칠 수 있으며, 다른 사람의 의견을 원할 경우 직접 토론을 발제할 수 있습니다.\n",
    "\n",
    "최근 변경\n",
    "12:27트랜스포머 애니메이티드\n",
    "12:27극장판 검정고무신: 즐거운 나의 집\n",
    "12:27걸그룹/포지션\n",
    "12:27대한민국의 젠더 분쟁\n",
    "12:26버크셔 해서웨이\n",
    "12:26람 나트 코빈드\n",
    "12:26Lateral\n",
    "12:26제1경비단\n",
    "12:26유머 1번지\n",
    "12:26윤석열 대통령의 조 바이든 미국 대통령 회담 후 욕설 발언 논란\n",
    "12:26Star Walkin’\n",
    "12:26스타크래프트/승률 상승 가이드/뉴비 단계\n",
    "12:26해군(원피스)\n",
    "12:26도박 중독\n",
    "12:26SsethTzeentach\n",
    "[더 보기]\n",
    "\n",
    "나무뉴스\n",
    "尹대통령, 바이든과 48초 '스탠딩 환담'…정식회담은 불발된 듯\n",
    "주호영, 野 7대 입법과제에 \"무책임·선심 남발\"…입법 저지키로\n",
    "BTS 측, 부산콘서트 비용 논란 진화…\"국가 기여 의지로 참여\"\n",
    "영탁 측 \"유튜버 이진호, 검찰 송치…예천양조 피소 건 '혐의없음'\" [전문]\n",
    "'GTA 6' 정보 누출에 FBI 출동...'디아블로4'도 영상 누출\n",
    "[더 보기]\n",
    "\n",
    "namu.wikiContáctenosTérminos de usoOperado por umanle S.R.L.Hecho con <3 en Asunción, República del Paraguay\n",
    "\n",
    "Su zona horaria es Asia/SeoulImpulsado por the seed engine\n",
    "\n",
    "This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.\n",
    "This site is protected by hCaptcha and its Privacy Policy and Terms of Service apply.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kss\n",
      "  Using cached kss-6.0.4.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting emoji==1.2.0 (from kss)\n",
      "  Using cached emoji-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pecab (from kss)\n",
      "  Using cached pecab-1.0.8.tar.gz (26.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from kss) (3.3)\n",
      "Collecting jamo (from kss)\n",
      "  Using cached jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting hangul-jamo (from kss)\n",
      "  Using cached hangul_jamo-1.0.1-py3-none-any.whl.metadata (899 bytes)\n",
      "Collecting tossi (from kss)\n",
      "  Using cached tossi-0.3.1.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting distance (from kss)\n",
      "  Using cached Distance-0.1.3.tar.gz (180 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyyaml==6.0 (from kss)\n",
      "  Using cached PyYAML-6.0.tar.gz (124 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [54 lines of output]\n",
      "      running egg_info\n",
      "      writing lib\\PyYAML.egg-info\\PKG-INFO\n",
      "      writing dependency_links to lib\\PyYAML.egg-info\\dependency_links.txt\n",
      "      writing top-level names to lib\\PyYAML.egg-info\\top_level.txt\n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 389, in <module>\n",
      "          main()\n",
      "        File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 373, in main\n",
      "          json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 143, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=[])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 304, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 320, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 288, in <module>\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 117, in setup\n",
      "          return distutils.core.setup(**attrs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 186, in setup\n",
      "          return run_commands(dist)\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 202, in run_commands\n",
      "          dist.run_commands()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 983, in run_commands\n",
      "          self.run_command(cmd)\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 999, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 1002, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 312, in run\n",
      "          self.find_sources()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 320, in find_sources\n",
      "          mm.run()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 543, in run\n",
      "          self.add_defaults()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 581, in add_defaults\n",
      "          sdist.add_defaults(self)\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\command\\sdist.py\", line 109, in add_defaults\n",
      "          super().add_defaults()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\sdist.py\", line 239, in add_defaults\n",
      "          self._add_defaults_ext()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\sdist.py\", line 324, in _add_defaults_ext\n",
      "          self.filelist.extend(build_ext.get_source_files())\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"<string>\", line 204, in get_source_files\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-uj88idi0\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 120, in __getattr__\n",
      "          raise AttributeError(attr)\n",
      "      AttributeError: cython_sources\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkss\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 문장 토큰화 수행\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sentence_tokens \u001b[38;5;241m=\u001b[39m kss\u001b[38;5;241m.\u001b[39msplit_sentences(text\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kss'"
     ]
    }
   ],
   "source": [
    "import kss\n",
    "\n",
    "# 문장 토큰화 수행\n",
    "sentence_tokens = kss.split_sentences(text.replace('\\n', '.'))\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting kss\n",
      "  Using cached kss-6.0.4.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting emoji==1.2.0 (from kss)\n",
      "  Using cached emoji-1.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting pecab (from kss)\n",
      "  Using cached pecab-1.0.8.tar.gz (26.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from kss) (3.3)\n",
      "Collecting jamo (from kss)\n",
      "  Using cached jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting hangul-jamo (from kss)\n",
      "  Using cached hangul_jamo-1.0.1-py3-none-any.whl.metadata (899 bytes)\n",
      "Collecting tossi (from kss)\n",
      "  Using cached tossi-0.3.1.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting distance (from kss)\n",
      "  Using cached Distance-0.1.3.tar.gz (180 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyyaml==6.0 (from kss)\n",
      "  Using cached PyYAML-6.0.tar.gz (124 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [54 lines of output]\n",
      "      running egg_info\n",
      "      writing lib\\PyYAML.egg-info\\PKG-INFO\n",
      "      writing dependency_links to lib\\PyYAML.egg-info\\dependency_links.txt\n",
      "      writing top-level names to lib\\PyYAML.egg-info\\top_level.txt\n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 389, in <module>\n",
      "          main()\n",
      "        File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 373, in main\n",
      "          json_out[\"return_val\"] = hook(**hook_input[\"kwargs\"])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\user\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 143, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 334, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=[])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 304, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 320, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 288, in <module>\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 117, in setup\n",
      "          return distutils.core.setup(**attrs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 186, in setup\n",
      "          return run_commands(dist)\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 202, in run_commands\n",
      "          dist.run_commands()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 983, in run_commands\n",
      "          self.run_command(cmd)\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 999, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 1002, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 312, in run\n",
      "          self.find_sources()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 320, in find_sources\n",
      "          mm.run()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 543, in run\n",
      "          self.add_defaults()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 581, in add_defaults\n",
      "          sdist.add_defaults(self)\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\command\\sdist.py\", line 109, in add_defaults\n",
      "          super().add_defaults()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\sdist.py\", line 239, in add_defaults\n",
      "          self._add_defaults_ext()\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\sdist.py\", line 324, in _add_defaults_ext\n",
      "          self.filelist.extend(build_ext.get_source_files())\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"<string>\", line 204, in get_source_files\n",
      "        File \"C:\\Users\\user\\AppData\\Local\\Temp\\pip-build-env-1lc7l_nu\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 120, in __getattr__\n",
      "          raise AttributeError(attr)\n",
      "      AttributeError: cython_sources\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 아나콘다 환경에서는 설치가... 힘든에ㅛ\n",
    "\n",
    "pip install kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
